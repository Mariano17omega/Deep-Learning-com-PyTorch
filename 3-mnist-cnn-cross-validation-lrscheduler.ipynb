{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Rede Neural Convolucional (Convolutional Neural Network - CNN)\n## Autor: Mariano F.M.A.S.\n### Data: 22/07/2023\n\n\nNeste notebook, exploramos como otimizar e melhorar o treinamento de um modelo de Rede Neural Convolucional (CNN) usando PyTorch. Reaproveitamos parte das função construidas em `2-neural-network-mnist-digit-recognizer-cnn`.","metadata":{"papermill":{"duration":0.014852,"end_time":"2023-07-11T16:24:42.594584","exception":false,"start_time":"2023-07-11T16:24:42.579732","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Objetivos:\n\n- Aumenta o cojunto de dados criando dadasets com diferentes com transforms.\n\n- Aumenta o cojunto de dados criando dadasets com ruído.\n\n- Aplicar a otimização Dropout.\n\n- Aplicar a otimização L2 no Modelo. \n\n- Aplicar a validação cruzada (cross-validation) no treinamento.\n\n\n# Biblioteca\"transforms\" \n\nA biblioteca \"transforms\" do torchvision é uma parte importante da biblioteca de visão computacional PyTorch (torchvision). Essa biblioteca fornece uma variedade de transformações pré-definidas que podem ser aplicadas a imagens ou dados antes ou durante o treinamento de modelos de aprendizado de máquina, especialmente em tarefas de visão computacional.\n\nAs transformações do torchvision são frequentemente usadas em conjunto com o DataLoader do PyTorch para preparar e pré-processar dados antes de alimentá-los aos modelos. Elas são especialmente úteis quando se trabalha com conjuntos de dados complexos ou quando é necessário realizar várias operações de pré-processamento em lotes de dados.\n\nAlguns exemplos comuns de transformações disponíveis na biblioteca \"transforms\" do torchvision incluem:\n\n1. **Resizing (Redimensionamento)**: Permite redimensionar as imagens para um tamanho específico, para que todas tenham a mesma dimensão.\n\n2. **Cropping (Corte)**: Corta uma região específica da imagem, útil para extrair uma região de interesse ou para data augmentation (aumento de dados).\n\n3. **Flipping (Inversão)**: Realiza inversões horizontais ou verticais nas imagens, o que também é usado para data augmentation.\n\n4. **Rotating (Rotação)**: Rotaciona a imagem em um determinado ângulo, útil para aumentar a variedade de orientações nas imagens de treinamento.\n\n5. **Normalização**: Normaliza as intensidades dos pixels da imagem, geralmente subtraindo a média e dividindo pelo desvio padrão, para facilitar o treinamento.\n\n6. **Conversão em tensor**: Converte a imagem em um tensor do PyTorch, pois os modelos do PyTorch trabalham com tensores.\n\nEssas são apenas algumas das transformações disponíveis. Existem muitas outras transformações úteis para diferentes tarefas e necessidades específicas.\n \n#  Ruído Gaussiano \nCriar ruído gaussiano em uma imagem significa adicionar variações aleatórias aos valores dos pixels da imagem seguindo uma distribuição normal (gaussiana). Essas variações aleatórias são representadas como amostras de uma distribuição normal com média zero e um desvio padrão específico.\n\nA distribuição normal, também conhecida como distribuição gaussiana, é uma distribuição estatística que é simétrica em torno de sua média, formando uma curva em forma de sino. Ela é caracterizada pelos parâmetros média (μ) e desvio padrão (σ).\n\nQuando adicionamos ruído gaussiano a uma imagem, estamos inserindo valores aleatórios com uma certa magnitude (amplitude) para cada pixel da imagem, resultando em pequenas variações na intensidade dos pixels. Essas variações são controladas pelo desvio padrão do ruído gaussiano.\n\nOs efeitos do ruído gaussiano dependem do desvio padrão escolhido. Um desvio padrão maior resultará em variações mais pronunciadas e, portanto, em um ruído mais perceptível na imagem.\n\nAdicionar ruído gaussiano a imagens pode ser útil em várias situações, como:\n\n1. Simulação de ambientes ruidosos para testar a robustez de algoritmos de processamento de imagens.\n\n2. Aumento de dados (data augmentation) durante o treinamento de modelos de visão computacional, tornando-os mais robustos em relação a variações nas imagens de entrada.\n\n3. Estudo e análise de métodos de filtragem e remoção de ruído.\n\n\n \n# Dropout\n\nA otimização Dropout é uma técnica utilizada para evitar o overfitting e melhorar a generalização do modelo. O overfitting ocorre quando um modelo de rede neural se torna muito especializado nos dados de treinamento e tem dificuldade em generalizar para novos dados. Isso pode acontecer quando a rede se torna muito complexa e memoriza os detalhes específicos dos exemplos de treinamento, em vez de aprender padrões gerais que se aplicam a novos dados.\n\nO Dropout é uma abordagem simples, porém eficaz, para mitigar o overfitting. Durante o treinamento da rede neural, o Dropout desativa aleatoriamente (com probabilidade p) um conjunto de unidades (neurônios) em cada camada. Isso significa que essas unidades não serão atualizadas e não contribuirão para o processo de aprendizado nessa iteração específica.\n\nEsse processo de desativação aleatória força a rede neural a ser mais robusta e evita que unidades específicas se tornem excessivamente dependentes de outras unidades para a correção de erros. Dessa forma, a rede neural é incentivada a aprender representações mais independentes e generalizáveis dos dados.\n\nDurante a fase de inferência ou teste, o Dropout não é aplicado, e todas as unidades da rede estão ativas. No entanto, os pesos da rede são ajustados para compensar o efeito do Dropout, de modo que o modelo retorne resultados precisos durante a inferência.\n \n\n# Regularização L1 e L2\n\n**Regularização L1 (Lasso):**\n- Objetivo: Evitar o overfitting e selecionar características importantes.\n- O que faz: Adiciona um termo à função de perda proporcional à soma dos valores absolutos dos coeficientes dos parâmetros do modelo.\n- Impacto nos coeficientes: Pode tornar alguns coeficientes exatamente zero, eliminando características irrelevantes.\n- Seleção de recursos: Ajuda a identificar quais recursos são mais importantes para o modelo.\n- Uso: Útil quando suspeitamos que muitos recursos sejam irrelevantes.\n\n**Regularização L2 (Ridge):**\n- Objetivo: Evitar o overfitting e tornar o modelo mais robusto.\n- O que faz: Adiciona um termo à função de perda proporcional à soma dos quadrados dos coeficientes dos parâmetros do modelo.\n- Impacto nos coeficientes: Diminui o impacto dos coeficientes, mas não os torna exatamente zero.\n- Espalhamento dos valores: Tende a espalhar os valores dos parâmetros, evitando que fiquem muito grandes.\n- Uso: Útil para evitar que o modelo seja muito sensível a pequenas variações nos dados de treinamento.\n- A Regularização L2 é aplicada através do uso do argumento `weight_decay` em um otimizador. O valor de weight_decay controla o termo de regularização L2 adicionado ao otimizador.\n\n**Escolhendo entre L1 e L2:**\n- Regularização L1 é útil quando se suspeita que muitos recursos sejam irrelevantes e queremos selecionar os mais importantes.\n- Regularização L2 é mais comum e geralmente funciona bem em muitos casos, evitando o overfitting e tornando o modelo mais estável.\n\n**Elastic Net:**\n- Além de L1 e L2, existe uma combinação chamada Elastic Net, que combina as duas regularizações.\n- Elastic Net controla a força de ambas as regularizações com dois hiperparâmetros: um para L1 e outro para L2.\n \n# Validação Cruzada (Cross-Validation)\n\nA validação cruzada (cross-validation) é uma técnica usada para avaliar o desempenho de um modelo de aprendizado de máquina e estimar como ele irá se comportar em dados não vistos. Essa técnica é especialmente útil quando se tem um conjunto limitado de dados para treinamento e é necessário obter uma estimativa mais robusta do desempenho do modelo.\n\nO processo de validação cruzada envolve a divisão do conjunto de dados em subconjuntos de treinamento e teste, permitindo que o modelo seja treinado e avaliado várias vezes com diferentes divisões dos dados. A ideia básica é a seguinte:\n\n1. Divisão dos dados: O conjunto de dados é dividido em k subconjuntos (ou \"dobras\") de aproximadamente o mesmo tamanho. Por exemplo, se escolhermos k = 5, o conjunto de dados será dividido em 5 partes.\n\n2. Treinamento e teste: O modelo é treinado k vezes. Em cada iteração, um dos k subconjuntos é usado como conjunto de teste, enquanto os outros k-1 subconjuntos são usados como conjunto de treinamento.\n\n3. Avaliação do desempenho: Em cada iteração, o modelo é avaliado no conjunto de teste, e as métricas de desempenho, como acurácia, precisão, recall ou outras métricas relevantes para o problema, são registradas.\n\n4. Média dos resultados: Ao final das k iterações, a média das métricas de desempenho é calculada, fornecendo uma estimativa geral do desempenho do modelo.\n\nO método mais comum de validação cruzada é a validação cruzada k-fold (k-fold cross-validation). Nesse método, os dados são divididos em k partes de tamanhos semelhantes, e o modelo é treinado e avaliado k vezes, cada vez usando um conjunto diferente como conjunto de teste. A média das métricas de desempenho calculadas nas k iterações é considerada uma estimativa mais robusta do desempenho do modelo em dados não vistos.\n\nA validação cruzada é uma técnica fundamental para evitar o overfitting e obter uma estimativa mais confiável do desempenho do modelo. Ela é especialmente importante quando se trabalha com conjuntos de dados pequenos ou quando a distribuição dos dados não é representativa em relação aos dados futuros que o modelo encontrará.\n ","metadata":{}},{"cell_type":"markdown","source":"# Rede Neural Convolucional (Convolutional Neural Network - CNN)\n ","metadata":{"papermill":{"duration":0.011376,"end_time":"2023-07-11T16:24:42.618509","exception":false,"start_time":"2023-07-11T16:24:42.607133","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport scipy\nimport pandas as pd\nimport seaborn as sns\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve, matthews_corrcoef, cohen_kappa_score, classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc  \n#from itertools import cycle \n \n    \nfrom PIL import Image\nfrom torch.utils.data import Subset\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n    \n# Checking GPU is available \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Training on device: \", device)\n\n","metadata":{"papermill":{"duration":5.473168,"end_time":"2023-07-11T16:24:48.150180","exception":false,"start_time":"2023-07-11T16:24:42.677012","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-26T02:52:55.650877Z","iopub.execute_input":"2023-07-26T02:52:55.651792Z","iopub.status.idle":"2023-07-26T02:52:55.671271Z","shell.execute_reply.started":"2023-07-26T02:52:55.651741Z","shell.execute_reply":"2023-07-26T02:52:55.669474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Carregando os dados","metadata":{"papermill":{"duration":0.011479,"end_time":"2023-07-11T16:24:48.173770","exception":false,"start_time":"2023-07-11T16:24:48.162291","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Importando os dados\n\n# Dados de treinamento  \ntrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n# Dados para validação do modelo\ntest_data  = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\n\n# Dados de treinamento \n#train = pd.read_csv('digit-recognizer/train.csv')\n# Dados para validação do modelo\n#test_data  = pd.read_csv('digit-recognizer/test.csv')\n\n","metadata":{"papermill":{"duration":7.537171,"end_time":"2023-07-11T16:24:55.761429","exception":false,"start_time":"2023-07-11T16:24:48.224258","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-26T02:52:58.789551Z","iopub.execute_input":"2023-07-26T02:52:58.789998Z","iopub.status.idle":"2023-07-26T02:53:04.660564Z","shell.execute_reply.started":"2023-07-26T02:52:58.789966Z","shell.execute_reply":"2023-07-26T02:53:04.659120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"papermill":{"duration":0.011841,"end_time":"2023-07-11T16:24:55.785386","exception":false,"start_time":"2023-07-11T16:24:55.773545","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-26T02:53:04.662851Z","iopub.execute_input":"2023-07-26T02:53:04.663219Z","iopub.status.idle":"2023-07-26T02:53:04.704735Z","shell.execute_reply.started":"2023-07-26T02:53:04.663187Z","shell.execute_reply":"2023-07-26T02:53:04.703514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Criando os Dataset \n\nAgora estaremos usando os dados como imagens (matrizes de pixels) invés de vetores (1D), então modificamos o retorno da função Dataset.\n\nO método `reshape()` é usado para alterar a forma de um array sem alterar seus dados. Ele retorna um array que contém os mesmos dados que o array original, mas com uma nova forma.\n\nNo caso, `.reshape((1, 28, 28))` está alterando a forma do array para ter uma forma de `(1, 28, 28)`. Isso significa que o array resultante terá três dimensões, com o tamanho da primeira dimensão sendo 1, o tamanho da segunda dimensão sendo 28 e o tamanho da terceira dimensão sendo 28.\n\nEm termos de imagens, isso geralmente é usado para formatar uma imagem plana 1D em uma imagem 2D. No conjunto de dados MNIST cada imagem é de 28x28 pixels, mas as imagens são armazenadas como arrays 1D de 784 elementos. Então, `.reshape((1, 28, 28))` está reformatando essa imagem 1D em uma imagem 2D de 28x28 pixels. A dimensão extra (1) é usada para indicar o número de canais de cor na imagem. Neste caso, é 1 porque as imagens MNIST são em escala de cinza e, portanto, têm apenas um canal de cor.\n\n### Transforms - RandomAffine\n\n**Função `transforms.RandomAffine`:**\nA função `transforms.RandomAffine` é uma transformação de data augmentation (aumento de dados) disponível na biblioteca `transforms` do torchvision, que é amplamente utilizada em tarefas de visão computacional. Essa transformação aplica uma combinação de translações, rotações, escalas e cisalhamentos aleatórios nas imagens durante o treinamento do modelo. Isso é útil para aumentar a variedade dos dados de treinamento e melhorar a capacidade de generalização do modelo.\n\n**Parâmetros:**\nA função `transforms.RandomAffine` aceita vários parâmetros que controlam a quantidade e o tipo de transformações aleatórias aplicadas nas imagens. Os principais parâmetros são os seguintes:\n\n1. `degrees`: Define o intervalo de rotação aleatória em graus. Por exemplo, `degrees=(-15, 15)` fará com que a imagem seja rotacionada aleatoriamente entre -15 e 15 graus.\n\n2. `translate`: Define o intervalo de translação aleatória em pixels. Por exemplo, `translate=(0.1, 0.1)` permitirá uma translação aleatória de até 10% da altura e largura da imagem.\n\n3. `scale`: Define o intervalo de escalas aleatórias. Por exemplo, `scale=(0.8, 1.2)` fará com que a imagem seja escalada aleatoriamente entre 80% e 120% do tamanho original.\n\n4. `shear`: Define o intervalo de cisalhamento aleatório em graus. Por exemplo, `shear=(-10, 10)` fará com que a imagem seja inclinada aleatoriamente entre -10 e 10 graus.\n\n**Funcionamento:**\nQuando aplicada a uma imagem, a função `transforms.RandomAffine` seleciona aleatoriamente os parâmetros de rotação, translação, escala e cisalhamento de acordo com os intervalos especificados nos parâmetros. Em seguida, ela aplica essas transformações à imagem, gerando uma nova imagem aumentada. O modelo é então treinado usando essa nova imagem, juntamente com as outras transformações e os dados originais.\n \n \n \n\n#### interpolation\n\nO parâmetro `interpolation` em `transforms.RandomAffine` e outras transformações de imagem no PyTorch define o método de interpolação a ser usado durante as transformações geométricas. A interpolação é um processo utilizado para estimar os valores de pixels em uma imagem após uma transformação que resulta em posições de pixel não inteiras.\n\nQuando aplicamos transformações como rotação, translação, escala ou cisalhamento em uma imagem, os pixels originais podem se mover para posições não inteiras na imagem transformada. Para determinar os valores de pixel nessas novas posições, é necessário realizar um cálculo de interpolação, que é uma estimativa baseada nos valores dos pixels vizinhos na imagem original.\n\nO parâmetro `interpolation` pode receber um dos seguintes valores:\n\n- `False` (padrão): Isso significa que a interpolação bilinear será usada. A interpolação bilinear estima os valores dos pixels na imagem transformada através de uma média ponderada dos quatro pixels vizinhos mais próximos. É um método de interpolação suave e é adequado para a maioria das transformações geométricas.\n\n- `Image.NEAREST`: Isso indica o método de interpolação de vizinho mais próximo, também conhecido como interpolação por pixel mais próximo. Nesse método, o valor do pixel mais próximo na imagem original é atribuído ao novo pixel na imagem transformada. Essa interpolação é rápida e útil quando você deseja preservar características distintas e nítidas nas imagens, mas pode levar a resultados menos suaves em algumas transformações.\n\n- `Image.BOX`: Isso usa a interpolação da média de caixa (box averaging), que é similar à interpolação bilinear, mas considera uma área maior de pixels vizinhos. Ela é ligeiramente mais rápida do que a interpolação bilinear, mas pode resultar em resultados menos suaves.\n\n- `Image.BILINEAR`: Este é o mesmo que usar `False`, ou seja, a interpolação bilinear será usada.\n\n- `Image.HAMMING`: Usa a interpolação de janela de Hamming, que é uma variação da interpolação bilinear. Pode ser mais suave que a interpolação bilinear, mas é mais lenta.\n\n- `Image.BICUBIC`: Usa a interpolação bicúbica, que leva em consideração 16 pixels vizinhos para estimar o novo valor do pixel. É uma interpolação mais precisa, mas mais lenta que a bilinear.\n\nCada método de interpolação tem suas próprias características e é mais adequado para diferentes tipos de transformações e efeitos desejados. Em geral, a interpolação bilinear é amplamente usada e fornece resultados satisfatórios na maioria dos casos. Se você tiver necessidades específicas ou quiser obter resultados mais nítidos ou suaves, pode experimentar diferentes métodos de interpolação.\n\nPara imagens em preto e branco (ou monocromáticas), geralmente o método de interpolação mais adequado é o `Image.NEAREST`, também conhecido como interpolação por vizinho mais próximo.\n\nO método `Image.NEAREST` atribui a cada novo pixel na imagem transformada o valor do pixel mais próximo na imagem original. Isso significa que a interpolação preservará as características distintas da imagem original e produzirá resultados nítidos e sem suavização. Como as imagens em preto e branco geralmente têm contornos claros e definidos, esse método de interpolação é adequado para preservar essas características importantes.\n\nA interpolação bilinear (usada por padrão quando `interpolation=False` ou `Image.BILINEAR`) leva em consideração uma área maior de pixels vizinhos para estimar os novos valores de pixel. Isso pode suavizar as bordas e detalhes nas imagens em preto e branco, o que pode não ser desejado, especialmente se você deseja manter a nitidez das características distintas.\n\nPortanto, se você está trabalhando com imagens em preto e branco e deseja preservar a nitidez das características, é recomendado usar `interpolation=Image.NEAREST` ao aplicar transformações geométricas como rotação, translação, escala ou cisalhamento. Isso garantirá que as transformações sejam aplicadas sem suavização e que a aparência geral da imagem preto e branco seja preservada.","metadata":{"papermill":{"duration":0.01191,"end_time":"2023-07-11T16:24:55.809110","exception":false,"start_time":"2023-07-11T16:24:55.797200","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class MNISTDataset(Dataset):\n    def __init__(self, data, transform=None, add_noise=False, noise_mean=0, noise_std=0.1):\n        \"\"\"\n        Inicialização da classe MNISTDataset.\n\n        Parâmetros:\n        - data: DataFrame contendo os dados do conjunto de dados MNIST.\n        - transform: Objeto de transformação para aplicar nas imagens (opcional).\n        - add_noise: Booleano que indica se deseja adicionar ruído gaussiano às imagens (opcional).\n        - noise_mean: Média do ruído gaussiano (padrão é 0, opcional).\n        - noise_std: Desvio padrão do ruído gaussiano (padrão é 0.1, opcional).\n        \"\"\"\n        self.data = data\n        self.transform = transform\n        self.add_noise = add_noise\n        self.noise_mean = noise_mean\n        self.noise_std = noise_std\n\n    def __len__(self):\n        \"\"\"\n        Retorna o tamanho do dataset, ou seja, o número de amostras.\n        \"\"\"\n        return len(self.data)\n\n    def __getitem__(self, index):\n        \"\"\"\n        Retorna uma amostra do dataset no índice especificado.\n\n        Parâmetros:\n        - index: O índice da amostra a ser retornada.\n\n        Retorna:\n        - image: A imagem da amostra como um tensor PyTorch.\n        - label: O rótulo da amostra como um tensor PyTorch (classe da imagem).\n        \"\"\"\n        # Converte os valores dos pixels da imagem em um tensor PyTorch normalizado no intervalo [0, 1]\n        image = torch.tensor(self.data.iloc[index, 1:].values.astype(float).reshape((1, 28, 28)) / 255.0, dtype=torch.float32)\n\n        # Obtém o rótulo da imagem como um tensor PyTorch\n        label = torch.tensor(self.data.iloc[index, 0], dtype=torch.long)\n\n        if self.add_noise:\n            # Adiciona ruído gaussiano à imagem usando a biblioteca NumPy\n            noise = np.random.normal(self.noise_mean, self.noise_std, size=image.shape)\n            image = image + torch.tensor(noise, dtype=torch.float32)\n\n        if self.transform is not None:\n            # Aplica a transformação especificada (se houver) na imagem\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2023-07-26T02:53:08.720887Z","iopub.execute_input":"2023-07-26T02:53:08.721372Z","iopub.status.idle":"2023-07-26T02:53:08.734731Z","shell.execute_reply.started":"2023-07-26T02:53:08.721330Z","shell.execute_reply":"2023-07-26T02:53:08.733399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define a transformação RandomAffine com rotação de -30 a 30 graus, translação de -20% a 20% do tamanho da imagem,\n# escala de 0.7 a 1.3 e um cisalhamento com um ângulo de -10 a 10 graus no sentido horizontal\n\ntransform_affine = transforms.RandomAffine(degrees=30, \n                                           translate=(0.2, 0.2), \n                                           scale=(0.7, 1.2), \n                                           shear=(-10, 10), \n                                           interpolation=Image.NEAREST)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-26T02:53:14.320064Z","iopub.execute_input":"2023-07-26T02:53:14.320595Z","iopub.status.idle":"2023-07-26T02:53:14.327385Z","shell.execute_reply.started":"2023-07-26T02:53:14.320558Z","shell.execute_reply":"2023-07-26T02:53:14.326457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Criando os dataloaders de Validação Sem transform e sem Noise\n#val_dataset_CNN = MNISTDataset_CNN(val,transform=None, add_noise=False, noise_mean=0, noise_std=0.1)\n\n#val_loader_CNN = DataLoader(val_dataset_CNN, batch_size=64, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T07:26:23.223947Z","iopub.execute_input":"2023-07-25T07:26:23.225022Z","iopub.status.idle":"2023-07-25T07:26:23.230390Z","shell.execute_reply.started":"2023-07-25T07:26:23.224979Z","shell.execute_reply":"2023-07-25T07:26:23.229219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_dataset Sem transform e sem Noise\ntrain_dataset_original = MNISTDataset(train,transform=None, add_noise=False, noise_mean=None, noise_std=None) \n\n# NOISE\ntrain_dataset_noise = MNISTDataset(train,transform=None, add_noise=True, noise_mean=0, noise_std=0.009)\n\n#transform_affine\ntrain_dataset_affine = MNISTDataset(train,transform=transform_affine, add_noise=False, noise_mean=None, noise_std=None)\n\n\n############################\n# Criando os dataloaders \ndataset_concat_train = ConcatDataset([train_dataset_original,train_dataset_noise, train_dataset_affine])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-26T02:53:16.869662Z","iopub.execute_input":"2023-07-26T02:53:16.870168Z","iopub.status.idle":"2023-07-26T02:53:16.878805Z","shell.execute_reply.started":"2023-07-26T02:53:16.870130Z","shell.execute_reply":"2023-07-26T02:53:16.877250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizando os Dados de Treinamento","metadata":{"papermill":{"duration":0.011764,"end_time":"2023-07-11T16:24:55.931006","exception":false,"start_time":"2023-07-11T16:24:55.919242","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#train_dataset_original\ntrain_loader_CNN = DataLoader(dataset_concat_train, batch_size=64, shuffle=True )\n \n \nfig, axis = plt.subplots(3, 5, figsize=(10, 7))\n\nfor images, labels in train_loader_CNN:\n    for i, ax in enumerate(axis.flat):\n        image, label = images[i], labels[i]\n        \n        ax.imshow(image.view(28, 28), cmap='binary') # add imagem\n        ax.set(title = f\"{label}\") # add label\n    break  \n","metadata":{"papermill":{"duration":2.935547,"end_time":"2023-07-11T16:24:58.878649","exception":false,"start_time":"2023-07-11T16:24:55.943102","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-26T02:53:19.333521Z","iopub.execute_input":"2023-07-26T02:53:19.334943Z","iopub.status.idle":"2023-07-26T02:53:22.231095Z","shell.execute_reply.started":"2023-07-26T02:53:19.334893Z","shell.execute_reply":"2023-07-26T02:53:22.229875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset de Test","metadata":{}},{"cell_type":"code","source":"# Definindo a classe do dataset\nclass MNISTDataset_test(Dataset):\n    def __init__(self, test_data):\n        self.test_data = test_data\n    \n    def __len__(self):\n        return len(self.test_data)\n    \n    def __getitem__(self, index): \n        image = torch.tensor(self.test_data.iloc[index, :].values.astype(float).reshape((1, 28, 28))/255.0, dtype=torch.float32) \n       \n        return image\n\n# Criando o dataloader de test\ntest_dataset = MNISTDataset_test(test_data)\n \ntest_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n","metadata":{"papermill":{"duration":0.01153,"end_time":"2023-07-11T16:24:55.870835","exception":false,"start_time":"2023-07-11T16:24:55.859305","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-26T02:53:27.269708Z","iopub.execute_input":"2023-07-26T02:53:27.270928Z","iopub.status.idle":"2023-07-26T02:53:27.281410Z","shell.execute_reply.started":"2023-07-26T02:53:27.270878Z","shell.execute_reply":"2023-07-26T02:53:27.279944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Construindo um Modelo CNN \n\n## dropout\n \nPara implementar o dropout no PyTorch, você pode usar o `torch.nn.Dropout` camada. Esta camada tem um parâmetro `p`, que é a probabilidade de cada unidade ser desligada. Por exemplo, se `p` for 0,5, então 50% das unidades serão desligadas a cada época de treinamento.\n  ","metadata":{}},{"cell_type":"markdown","source":"# Treinamento com Validação Cruzada \n\n\nDefinimos uma função para fazer o treinamento com Validação Cruzada  de um modelo qualquer.\n\nEssa função vai treinar o modelo para dada fold, por infinitas epochs, até que a acurácia pare de aumentar após um determinado número de epocas dada por `patience`. Depois disso ele segue para o fold seguinte até treinar usando todos os folds.\n\nEm cada iteração, o modelo é avaliado no conjunto de teste, e as métricas de desempenho, como acurácia, precisão, recall ou outras métricas relevantes para o problema, são registradas. Ao final das k iterações, a média das métricas de desempenho é calculada, fornecendo uma estimativa geral do desempenho do modelo.\n","metadata":{}},{"cell_type":"code","source":"def validate(model, val_loader, criterion):\n    model.eval()  # Defina o modelo para o modo de avaliação\n    correct = 0\n    total = 0\n    validation_loss = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            validation_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)   #Encontra o índice da probabilidade máxima\n            # A função torch.max() retorna dois valores: o primeiro é o valor máximo encontrado em cada coluna do tensor\n            #e o segundo é o índice do valor máximo em cada coluna. ex.: [0.2, 0.4, 0.9, 0.5] => (0.9, 2)= (valor máximo,índice)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = (correct / total) * 100\n    validation_loss = validation_loss / len(val_loader)  # Media de loss\n\n    model.train()  # Define o modelo de volta ao modo de treinamento\n\n    return accuracy, validation_loss, loss\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-26T02:53:30.889617Z","iopub.execute_input":"2023-07-26T02:53:30.890046Z","iopub.status.idle":"2023-07-26T02:53:30.900911Z","shell.execute_reply.started":"2023-07-26T02:53:30.890014Z","shell.execute_reply":"2023-07-26T02:53:30.899383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def record_preds_fold(model, val_loader):  \n    model.eval()  # Set the model to evaluation mode\n    true_labels = []\n    predictions = []\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            true_labels.extend(labels.detach().cpu().numpy())\n            predictions.extend(predicted.detach().cpu().numpy())\n    model.train()  # Define o modelo de volta ao modo de treinamento\n    return predictions, true_labels\n\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-26T02:53:35.767510Z","iopub.execute_input":"2023-07-26T02:53:35.767981Z","iopub.status.idle":"2023-07-26T02:53:35.777169Z","shell.execute_reply.started":"2023-07-26T02:53:35.767946Z","shell.execute_reply":"2023-07-26T02:53:35.775929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"all_true_labels.append(true_labels_val.numpy())\nall_predictions.append(predicted_val.numpy())\n\nResulta em uma lista com os all_predictions e all_true_labels de cada fold\n\ndepois será nescesario fazer um loop all_predictions e all_true_labels para calcular as metricas e depois fazer a media.","metadata":{"execution":{"iopub.status.busy":"2023-07-23T03:41:38.162045Z","iopub.execute_input":"2023-07-23T03:41:38.162436Z","iopub.status.idle":"2023-07-23T03:41:38.169884Z","shell.execute_reply.started":"2023-07-23T03:41:38.162409Z","shell.execute_reply":"2023-07-23T03:41:38.168955Z"}}},{"cell_type":"markdown","source":"# Modelo","metadata":{}},{"cell_type":"code","source":"\nclass MNISTModel_CNN_2(nn.Module):\n    def __init__(self):\n        super(MNISTModel_CNN_2, self).__init__()\n\n        # Camadas convolucionais\n        self.conv_layers = nn.ModuleList([\n            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(8),\n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size=4, stride=2),\n            \n\n            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),#\n            nn.Dropout2d(0.1), #\n            nn.MaxPool2d(kernel_size=3, stride=1),\n            \n            \n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),#\n            nn.Dropout2d(0.1),#\n            nn.MaxPool2d(kernel_size=2, stride=1)\n        ])\n\n        # Calcula a dimensão de entrada das camadas totalmente conectadas\n        self.fc_input_dim = self.calculate_fc_input_dim()\n \n        # Camadas totalmente conectadas com Dropout\n        self.fc_layers = nn.ModuleList([\n            nn.Linear(self.fc_input_dim, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.1),  # Adiciona Dropout com taxa de 0.1\n            \n            nn.Linear(1024, 768),\n            nn.ReLU(),\n            nn.Dropout(0.2),  # Adiciona Dropout com taxa de 0.2\n            \n            nn.Linear(768, 512),\n            nn.ReLU(),\n            nn.Dropout(0.2),  # Adiciona Dropout com taxa de 0.2\n            \n            nn.Linear(512, 400),\n            nn.ReLU(),\n            nn.Dropout(0.2),  # Adiciona Dropout com taxa de 0.2\n            \n            nn.Linear(400, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),  # Adiciona Dropout com taxa de 0.1\n\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.1),  # Adiciona Dropout com taxa de 0.1\n\n            nn.Linear(128, 10)\n        ])\n        \n        \n    def forward(self, x):\n        for layer in self.conv_layers:\n            x = layer(x)\n\n        x = x.view(-1, self.fc_input_dim)\n        for layer in self.fc_layers:\n            x = layer(x)\n\n        return x\n\n    def calculate_fc_input_dim(self):\n        # Cria uma entrada de exemplo e passa pelas camadas convolucionais\n        example_input = torch.zeros(1, 1, 28, 28)\n        for layer in self.conv_layers:\n            example_input = layer(example_input)\n        # Obtém a forma da saída das camadas convolucionais\n        output_shape = example_input.shape\n        fc_input_dim = output_shape[1] * output_shape[2] * output_shape[3]\n        return fc_input_dim\n\nmodel = MNISTModel_CNN_2().to(device)\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-26T03:04:10.725848Z","iopub.execute_input":"2023-07-26T03:04:10.726331Z","iopub.status.idle":"2023-07-26T03:04:10.801169Z","shell.execute_reply.started":"2023-07-26T03:04:10.726293Z","shell.execute_reply":"2023-07-26T03:04:10.800115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# lr_scheduler \n\nNo PyTorch, o `lr_scheduler` (scheduler de taxa de aprendizado) é uma ferramenta poderosa para ajustar a taxa de aprendizado (learning rate) durante o treinamento de um modelo de aprendizado de máquina. A taxa de aprendizado é um hiperparâmetro crítico em algoritmos de otimização, como o gradiente descendente, e pode afetar significativamente o desempenho e a convergência do modelo.\n\nO `lr_scheduler` permite ajustar automaticamente a taxa de aprendizado em função do número de épocas (ou iterações) de treinamento. Isso é útil porque, em diferentes estágios do treinamento, pode ser benéfico reduzir a taxa de aprendizado para garantir uma convergência mais estável e precisa.\n\nExistem vários tipos de schedulers disponíveis no PyTorch, como `StepLR`, `MultiStepLR`, `ExponentialLR`, `CosineAnnealingLR`, entre outros. Cada um desses schedulers implementa uma estratégia diferente para ajustar a taxa de aprendizado. Por exemplo, o `StepLR` reduz a taxa de aprendizado em um fator multiplicativo após cada número fixo de épocas, enquanto o `CosineAnnealingLR` diminui a taxa de aprendizado seguindo um padrão cosseno.\n\nAqui está um exemplo simples de como usar o `lr_scheduler` no PyTorch:\n\n```python\nimport torch\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# Crie o seu modelo e dataloaders aqui\n\n# Defina o otimizador e o scheduler\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n# Loop de treinamento\nfor epoch in range(num_epochs):\n    # Treinamento\n    for batch in dataloader:\n        # Fazer o treinamento do modelo\n\n    # Atualizar o scheduler a cada época\n    scheduler.step()\n```\n\n# ReduceLROnPlateau\nO `ReduceLROnPlateau` é outro scheduler disponível no PyTorch que é projetado para ajustar automaticamente a taxa de aprendizado com base na evolução do desempenho do modelo durante o treinamento. Ele monitora uma métrica, como a perda de validação ou a precisão, e reduz a taxa de aprendizado quando a métrica de validação estagna.\n\nEssa abordagem é útil quando o modelo atinge um platô em seu desempenho, onde a métrica de validação não melhora significativamente. Nesse caso, diminuir a taxa de aprendizado pode ajudar o modelo a sair do platô e melhorar seu desempenho.\n\nAqui está um exemplo de como usar o `ReduceLROnPlateau` no PyTorch:\n\n```python\nimport torch\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# Crie o seu modelo e dataloaders aqui\n\n# Defina o otimizador e o scheduler\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n\n# Loop de treinamento\nfor epoch in range(num_epochs):\n    # Treinamento\n    for batch in dataloader:\n        # Fazer o treinamento do modelo\n\n    # Avaliar o desempenho do modelo na validação\n    loss_val = evaluate_model(model, dataloader_val)\n\n    # Atualizar o scheduler com base no desempenho da validação\n    scheduler.step(loss_val)\n```\n\nNeste exemplo, o scheduler `ReduceLROnPlateau` monitora a perda de validação (`loss_val`) e, se ela estagnar por um número especificado de épocas (definido por `patience`), reduz a taxa de aprendizado em um fator multiplicativo (definido por `factor`). O argumento `mode` indica se a métrica de validação deve ser minimizada ('min') ou maximizada ('max'). Neste caso, como é uma perda, usamos 'min'.\n\nO `lr_scheduler` é usado para definir uma estratégia de ajuste da taxa de aprendizado ao longo do treinamento, enquanto o `ReduceLROnPlateau` é usado para ajustar automaticamente a taxa de aprendizado com base na evolução do desempenho do modelo durante a validação. Isso pode ajudar a melhorar a estabilidade e o desempenho geral do modelo durante o treinamento.","metadata":{}},{"cell_type":"markdown","source":"## Treinamento Acelerado com ReduceLROnPlateau","metadata":{}},{"cell_type":"code","source":"\n \ndef train_kfolds_acel(model, criterion, optimizer, train_dataset, batch_size, num_folds, nf, patience, losses_batch,acc,scheduler_patience,scheduler_factor,scheduler_min_lr ):\n    fold_size = len(train_dataset) // num_folds  # Tamanho de cada fold\n    best_accuracy = 0.0\n    model.train()\n    epoch = 0\n\n    all_predictions = []\n    all_true_labels = []\n\n    for fold in range(num_folds):\n        if (fold)== nf:\n            break\n            \n        print(f\"Fold {fold+1}/{num_folds}\")\n\n        # Divide o conjunto de treinamento em folds de treinamento e validação\n        val_indices = range(fold * fold_size, (fold+1) * fold_size)\n        train_indices = [i for i in range(len(train_dataset)) if i not in val_indices]\n\n        train_subset = Subset(train_dataset, train_indices)\n        val_subset = Subset(train_dataset, val_indices)\n\n        train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n        val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n\n        #############\n        total_batches = len(train_loader)\n        batches_processed = 0\n        progress_threshold = total_batches // 20  # 20% do total de batches\n        #############\n\n        # Criar um scheduler ReduceLROnPlateau para reduzir a taxa de aprendizado\n        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=scheduler_factor, patience = scheduler_patience, min_lr = scheduler_min_lr, verbose=True)\n \n\n\n        epochs_without_improvement = 0\n        while True:\n            for batch_idx, (images, labels) in enumerate(train_loader):\n                images = images.to(device)\n                labels = labels.to(device)\n                # Forward pass\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                losses_batch.append(loss.item())\n\n                # Backward pass and optimization\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                ############\n                batches_processed += 1\n                # Verifica se chegou ao limite para imprimir o número do batch\n                if batches_processed % progress_threshold == 0:\n                    print(f\"Fold {fold+1}/{num_folds}, Epoch [{epoch+1}], Batch [{batch_idx+1}/{total_batches}],  Loss: {round(loss.item(), 5)},\")\n                ############\n\n            # Validação\n            accuracy, validation_loss, loss_val = validate(model, val_loader, criterion)\n            acc.append(accuracy)\n            print('Fold {}/{}, Epoch [{}], Loss: {:.4f}, Validation Loss: {:.4f}, Accuracy: {:.2f}%'.format(fold+1, num_folds, epoch+1, loss.item(), validation_loss, accuracy))\n            epoch += 1\n\n            # Calcule a métrica de desempenho (por exemplo, a perda) e passe para o scheduler\n            # Aqui, estamos usando a perda como a métrica de desempenho para o exemplo\n            scheduler.step(loss_val)\n            #scheduler.step(validation_loss.to(device))\n\n            # Verifica se a acurácia melhorou\n            if accuracy > best_accuracy :\n                best_accuracy = accuracy\n                epochs_without_improvement = 0\n                torch.save(model.state_dict(), f'best_model_fold{fold+1}.pth')  # Salva o modelo com a melhor acurácia para o fold atual\n            else:\n                epochs_without_improvement += 1\n\n            if epochs_without_improvement == patience:\n                # Após o treinamento, chama a função para registrar as previsões no conjunto de teste do fold atual\n                predicted_val, true_labels_val = record_preds_fold(model, val_loader)\n                all_predictions.append(predicted_val)  # Armazena as previsões e rótulos verdadeiros para todos os folds\n                all_true_labels.append(true_labels_val)\n                print('No improvement for fold {}.'.format(fold+1))\n                break\n            \n    print('Stopping training!')\n    return all_predictions, all_true_labels, losses_batch,acc\n","metadata":{"execution":{"iopub.status.busy":"2023-07-26T03:04:16.331885Z","iopub.execute_input":"2023-07-26T03:04:16.332372Z","iopub.status.idle":"2023-07-26T03:04:16.351737Z","shell.execute_reply.started":"2023-07-26T03:04:16.332332Z","shell.execute_reply":"2023-07-26T03:04:16.350729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses_batch = []  # Lista para armazenar os valores de loss durante todo o treinamento\nacc = [] \n# Criando os dataloaders  dataset_concat_train\n#dataset_concat_train = ConcatDataset([train_dataset, train_dataset_noise, train_dataset_affine])\n\nmodel = MNISTModel_CNN_2().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T03:04:17.759060Z","iopub.execute_input":"2023-07-26T03:04:17.759560Z","iopub.status.idle":"2023-07-26T03:04:17.824864Z","shell.execute_reply.started":"2023-07-26T03:04:17.759523Z","shell.execute_reply":"2023-07-26T03:04:17.823756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()       # Loss function \nparametes_model=model.parameters()\noptimizer = torch.optim.Adam(parametes_model, lr=1e-2, weight_decay=1e-4)  # Optimizer #L2 = weight_decay\n\nscheduler_patience = 3 #Epocas\nscheduler_factor = 0.1\nscheduler_min_lr=1e-8\nbatch_size= 1024\n\npatience = 6  # Número de épocas para esperar antes de parar\n\nnum_folds=8\nnf=1          \n# Se nf > num_folds -> Treinamendo usando todos os kfolds. Se nf=1 - > Treinamento usando apenas nf kfolds.\n\n\n\n\n     \nall_pred, all_true_lb, losses_batch_fold,acc_fold =train_kfolds_acel(model, \n                                                                     criterion, \n                                                                     optimizer, \n                                                                     dataset_concat_train, \n                                                                     batch_size, \n                                                                     num_folds, \n                                                                     nf,\n                                                                     patience,\n                                                                     losses_batch,\n                                                                     acc,\n                                                                     scheduler_patience,\n                                                                     scheduler_factor,\n                                                                     scheduler_min_lr)\n ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lista de valores de perda  \nloss_values = losses_batch\n\n# Épocas correspondentes (apenas para fins de exemplo)\nepochs = list(range(1, len(loss_values) + 1))\n\n# Plot do gráfico de perda em função das épocas\nplt.plot(epochs, loss_values, linestyle='-', color='b')\nplt.xlabel('Épocas')\nplt.ylabel('Loss')\nplt.title('Gráfico de Loss em função dos batchs')\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:13.599112Z","iopub.execute_input":"2023-07-24T20:25:13.599471Z","iopub.status.idle":"2023-07-24T20:25:13.880686Z","shell.execute_reply.started":"2023-07-24T20:25:13.599441Z","shell.execute_reply":"2023-07-24T20:25:13.879684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lista de valores de perda (exemplo)\nloss_values = acc\n\n# Épocas correspondentes (apenas para fins de exemplo)\nepochs = list(range(1, len(loss_values) + 1))\n\n# Plot do gráfico de perda em função das épocas\nplt.plot(epochs, loss_values, linestyle='-', color='b')\nplt.xlabel('Épocas')\nplt.ylabel('Loss')\nplt.title('Gráfico de acc em função das Épocas')\nplt.grid(True)\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Avaliação do Modelo\n\n##  Métricas de avaliação de modelos de classificação\n\nPara calcular as metricas de avaliação usamos os sequintes valores:\n\n**Verdadeiros Positivos (TP)**: Verdadeiros positivos são os casos em que o modelo previu a classe positiva corretamente. Em outras palavras, a classe real do exemplo era positiva e o modelo também previu a classe como positiva.\n\n**Falsos Positivos (FP)**: Falsos positivos são os casos em que o modelo previu incorretamente a classe positiva. Isso significa que a classe real do exemplo era negativa, mas o modelo previu a classe como positiva. Isso é também conhecido como um erro do Tipo I.\n\n**Verdadeiros Negativos (TN)**: Verdadeiros negativos são os casos em que o modelo previu a classe negativa corretamente. Em outras palavras, a classe real do exemplo era negativa e o modelo também previu a classe como negativa.\n\n**Falsos Negativos (FN)**: Falsos negativos são os casos em que o modelo previu incorretamente a classe negativa. Isso significa que a classe real do exemplo era positiva, mas o modelo previu a classe como negativa. Isso é também conhecido como um erro do Tipo II.\n\n\nEsses quatro valores formam a base da matriz de confusão. Além disso, várias métricas de avaliação, como precisão, recall e F1 score, são calculadas com base nesses valores. \n\n## Métricas\n\n\n1. **Accuracy (Acurácia)**: É a proporção de previsões corretas feitas pelo modelo em relação ao total de previsões. É uma métrica útil quando as classes estão bem balanceadas, mas pode ser enganosa quando as classes estão desbalanceadas. A fórmula para a acurácia é:\n\n   $$ \\text{Accuracy} = \\frac{\\text{Verdadeiros Positivos (TP) + Verdadeiros Negativos (TN)}}{\\text{Verdadeiros Positivos (TP) + Falsos Positivos (FP) + Verdadeiros Negativos (TN) + Falsos Negativos (FN)}} $$\n   \n\n\n2. **Precision (Precisão)**: É a proporção de previsões positivas que são realmente corretas. É uma métrica importante quando o custo de Falsos Positivos é alto. A fórmula para a precisão é:\n\n   $$ \\text{Precision} = \\frac{\\text{Verdadeiros Positivos (TP)}}{\\text{Verdadeiros Positivos (TP) + Falsos Positivos (FP)}} $$\n\n\n3. **Recall (Revocação ou Sensibilidade)**: É a proporção de positivos reais que foram identificados corretamente. É uma métrica importante quando o custo de Falsos Negativos é alto. A fórmula para o recall é:\n\n   $$ \\text{Recall} = \\frac{\\text{Verdadeiros Positivos (TP)}}{\\text{Verdadeiros Positivos (TP) + Falsos Negativos (FN)}} $$\n\n\n4. **F1 Score**: É a média harmônica entre a precisão e o recall. É uma métrica útil quando você precisa de um equilíbrio entre a precisão e o recall e há uma distribuição desigual de classes. A fórmula para o F1 Score é:\n\n   $$ \\text{F1 Score} = 2 * \\frac{\\text{Precision * Recall}}{\\text{Precision + Recall}} $$\n\n\nEssas métricas são comumente usadas para avaliar modelos de classificação e cada uma tem seus próprios pontos fortes e fracos, dependendo da situação específica.\n\n\n5. **Coeficiente de Kappa de Cohen**\n\nO coeficiente de Kappa de Cohen é uma estatística que é usada para medir a precisão de classificação em tarefas de classificação. É mais útil quando os dados são classificados por humanos, pois leva em consideração a possibilidade de o acordo ocorrer por acaso.\n\nO coeficiente de Kappa de Cohen varia de -1 a 1. Um valor de 1 indica que há um acordo perfeito entre os classificadores. Um valor de 0 indica que o acordo é o mesmo que seria esperado por acaso. Um valor negativo indica que o acordo é pior do que o aleatório.\n\nAqui está como o coeficiente de Kappa de Cohen é geralmente interpretado:\n\n- Valores ≤ 0: Nenhum acordo\n- 0.01–0.20: Nenhum a um leve acordo\n- 0.21–0.40: Acordo justo\n- 0.41–0.60: Acordo moderado\n- 0.61–0.80: Acordo substancial\n- 0.81–0.99: Acordo quase perfeito\n- 1: Acordo perfeito\n\nO coeficiente de Kappa de Cohen é uma medida mais robusta do que a simples porcentagem de concordância, porque leva em consideração a possibilidade de o acordo ocorrer por acaso. Isso é especialmente importante quando os dados estão desequilibrados.\n\n\n6. **Coeficiente de Correlação de Matthews (MCC)**\n\nO Coeficiente de Correlação de Matthews (MCC) é uma medida de qualidade para problemas de classificação binária. Ele leva em consideração verdadeiros e falsos positivos e negativos e é geralmente considerado uma medida equilibrada, o que significa que pode ser usado mesmo se as classes estiverem de tamanhos muito diferentes.\n\nO MCC é, em essência, uma correlação entre as observações reais e as previsões: um coeficiente de +1 representa uma previsão perfeita, 0 uma previsão média aleatória e -1 uma previsão inversa.\n\nA fórmula para o MCC é:\n\n$$ MCC = \\frac{(TP*TN - FP*FN) }{ \\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)} }$$\n\n\n\nO denominador da fórmula garante que o MCC sempre caia entre -1 e +1.\n\n7. **Matriz de Confusão**\n\nA Matriz de Confusão é uma tabela usada para descrever o desempenho de um modelo de classificação em um conjunto de dados para os quais os valores verdadeiros são conhecidos. Ela é chamada de matriz de confusão porque permite visualizar facilmente o tipo de confusão que o classificador está causando, mostrando onde o classificador está confundindo uma classe por outra.\n\n \n\nPara uma classificação binária a matriz de confusão é uma tabela 2x2. As linhas da matriz representam as classes reais, enquanto as colunas representam as classes previstas pelo modelo. A matriz é organizada da seguinte forma:\n\n\n|                     | **Previsto: Positivo** | **Previsto: Negativo** |\n|---------------------|------------------------|------------------------|\n| **Real: Positivo**  | Verdadeiros Positivos  | Falsos Negativos       |\n| **Real: Negativo**  | Falsos Positivos       | Verdadeiros Negativos  |\n\n\nA matriz de confusão é uma ferramenta poderosa para entender como seu modelo está performando e onde ele está cometendo erros. Além disso, muitas métricas de avaliação do modelo, como precisão, recall e F1 score, são calculadas com base nos valores da matriz de confusão.\n \n\n  ","metadata":{"papermill":{"duration":0.014408,"end_time":"2023-07-11T16:31:32.359921","exception":false,"start_time":"2023-07-11T16:31:32.345513","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#all_pred[0]# all_true_lb","metadata":{"papermill":{"duration":0.040838,"end_time":"2023-07-11T16:31:32.415712","exception":false,"start_time":"2023-07-11T16:31:32.374874","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-24T16:22:17.668371Z","iopub.execute_input":"2023-07-24T16:22:17.669374Z","iopub.status.idle":"2023-07-24T16:22:17.674482Z","shell.execute_reply.started":"2023-07-24T16:22:17.669328Z","shell.execute_reply":"2023-07-24T16:22:17.673556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef evaluate_model(predictions, true_labels): \n\n    # Accuracy\n    accuracy = accuracy_score(true_labels, predictions)\n    print(\"Accuracy: \",  round(accuracy, 3))\n\n    # Precision\n    precision = precision_score(true_labels, predictions, average='weighted')\n    print(\"Precision: \",  round(precision, 3))\n\n    # Recall\n    recall = recall_score(true_labels, predictions, average='weighted')\n    print(\"Recall: \",  round(recall, 3))\n\n    # F1 Score\n    f1 = f1_score(true_labels, predictions, average='weighted')\n    print(\"F1 Score: \",  round(f1, 3))\n    \n#############################################################\n#    Está desativado pq não é um problema de classificação binaria (temos 10 classes)\n#    # Matthews Correlation Coefficient (MCC)\n#    mcc = matthews_corrcoef(true_labels, predictions)\n#    print(\"Matthews Correlation Coefficient: \",  round(mcc, 3))\n#############################################################\n\n    # Cohen's Kappa\n    kappa = cohen_kappa_score(true_labels, predictions)\n    #interpret_kappa\n    print(\"Cohen's Kappa: \",    round(kappa, 3))\n    if kappa <= 0:\n        print (\"Nenhum acordo\")\n    elif kappa <= 0.20:\n        print (\"Nenhum a um leve acordo\")\n    elif kappa <= 0.40:\n        print (\"Acordo justo\")\n    elif kappa <= 0.60:\n        print (\"Acordo moderado\")\n    elif kappa <= 0.80:\n        print (\"Acordo substancial\")\n    elif kappa < 1:\n        print (\"Acordo quase perfeito\")\n    elif kappa == 1:\n        print (\"Acordo perfeito\")\n    else:\n        print (\"Valor de Kappa inválido\")\n\n\n\n    # Classification Report\n    report = classification_report(true_labels, predictions)\n    print(\"Classification Report:\\n\", report)\n\n    # Confusion Matrix\n    cm = confusion_matrix(true_labels, predictions)\n    #print(\"Confusion Matrix:\\n\", cm)\n    \n    # Plotting Confusion Matrix\n    plt.figure(figsize=(10,7))\n    sns.heatmap(cm, annot=True, fmt='d')\n    plt.xlabel('Predicted')\n    plt.ylabel('Truth')\n    plt.show()\n     \n \n \n\n","metadata":{"papermill":{"duration":0.035027,"end_time":"2023-07-11T16:31:32.465874","exception":false,"start_time":"2023-07-11T16:31:32.430847","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-24T20:25:30.199283Z","iopub.execute_input":"2023-07-24T20:25:30.199659Z","iopub.status.idle":"2023-07-24T20:25:30.213470Z","shell.execute_reply.started":"2023-07-24T20:25:30.199608Z","shell.execute_reply":"2023-07-24T20:25:30.212431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#evaluate_model(all_pred_concat, all_true_lb_s) #all_pred[0]# all_true_lb\nn=0 #n= numero do Fold \nevaluate_model(all_pred[n], all_true_lb[n])\n","metadata":{"papermill":{"duration":8.624643,"end_time":"2023-07-11T16:31:41.104953","exception":false,"start_time":"2023-07-11T16:31:32.480310","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-24T20:25:43.006878Z","iopub.execute_input":"2023-07-24T20:25:43.007266Z","iopub.status.idle":"2023-07-24T20:25:43.655200Z","shell.execute_reply.started":"2023-07-24T20:25:43.007235Z","shell.execute_reply":"2023-07-24T20:25:43.653329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prevendo e identificando erros","metadata":{}},{"cell_type":"code","source":"\ndef predict_and_identify_errors(model, val_loader):\n    model.eval()  # Defina o modelo para o modo de avaliação\n    correct = 0\n    total = 0\n    wrong_predictions = []\n\n    with torch.no_grad():  # Sem calcular gradientes  \n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images )  # Obtenha as previsões do modelo\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted.cpu() == labels.cpu()).sum().item()\n\n            # Identificar as previsões erradas\n            wrong_indices = (predicted.cpu()  != labels.cpu()).nonzero()[:, 0] \n            #.nonzero() retorna os índices dos elementos diferentes de zero. \n            wrong_images = images[wrong_indices].cpu()\n            wrong_labels = predicted[wrong_indices].cpu()\n            true_labels = labels[wrong_indices].cpu()\n            wrong_predictions.extend(list(zip(wrong_images, wrong_labels, true_labels)))\n\n \n    # Mostra as previsões erradas\n    print(\"Total de previsões erradas:\", total - correct )\n    print(\"Previsões erradas:\")\n    \n    # Para 2o imagens, dispostas em 2 linhas e 10 colunas\n    n_rows = 3\n    n_cols = 10\n    \n    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols, n_rows+0.3))  # Create a subplot with 1 row and 20 columns\n    axs_max=len(list(axs.flat))\n\n    for i, (img, wrong_label, true_label) in enumerate(wrong_predictions[:axs_max]): \n        # Calcula a linha e a coluna atual\n        row = i // n_cols\n        col = i % n_cols\n    \n        # Plot das imagens erradas\n        axs[row, col].imshow(img.view(28, 28), cmap='binary')\n        axs[row, col].axis('off')   \n        axs[row, col].set_title(f'P: {wrong_label.item()}, T: {true_label.item()}')  # Defina o título do subplot\n    plt.show()  # Show the plot\n\n\ntrain_loader_pd = DataLoader(train_dataset_original, batch_size=1024, shuffle=True )\n \npredict_and_identify_errors(model, train_loader_pd)\n#138\n#78\n\nlosses_batch = []  # Lista para armazenar os valores de loss durante todo o treinamento\nacc = [] \n\ncriterion = nn.CrossEntropyLoss()       # Loss function \nparametes_model=model.parameters()\n\n#L2 = weight_decay\noptimizer = torch.optim.Adam(parametes_model, lr=0.01, weight_decay=1e-4)  # Optimizer\n \n    \npatience = 6  # Número de épocas para esperar antes de parar\n\nnum_folds=8\nnf=2\nbatch_size= 1024\n\nscheduler_patience = 4 #Epocas\nscheduler_factor = 0.1\nscheduler_min_lr=1e-8\n\n     \nall_pred, all_true_lb, losses_batch_fold,acc_fold =train_kfolds_acel( model, \n                                         criterion, \n                                         optimizer, \n                                         dataset_concat_train, \n                                         batch_size, \n                                         num_folds, \n                                         nf,\n                                         patience,\n                                         losses_batch,\n                                         acc,\n                                         scheduler_patience,\n                                         scheduler_factor,\n                                         scheduler_min_lr)\n ","metadata":{"papermill":{"duration":0.033682,"end_time":"2023-07-11T16:31:41.189110","exception":false,"start_time":"2023-07-11T16:31:41.155428","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-24T20:26:03.252361Z","iopub.execute_input":"2023-07-24T20:26:03.253338Z","iopub.status.idle":"2023-07-24T20:26:13.813258Z","shell.execute_reply.started":"2023-07-24T20:26:03.253294Z","shell.execute_reply":"2023-07-24T20:26:13.812306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":5.352425,"end_time":"2023-07-11T16:31:46.558550","exception":false,"start_time":"2023-07-11T16:31:41.206125","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissão","metadata":{"papermill":{"duration":0.018985,"end_time":"2023-07-11T16:31:46.596510","exception":false,"start_time":"2023-07-11T16:31:46.577525","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\ndef submission_model(model, test_loader):\n    model.eval()  # Set the model to evaluation mode\n    predictions = []\n    with torch.no_grad():\n        for images in test_loader:\n            images = images.to(device)\n            outputs = model(images).cpu() \n            _, predicted = torch.max(outputs.data, 1)\n            predictions.extend(predicted.numpy())\n           # print('oi')\n        # Create a DataFrame with the predictions\n        df = pd.DataFrame(predictions, columns=['Label'])\n        df['Label'] = df['Label'].astype(int)  \n        df.index.name = 'ImageId'\n        df.index += 1  # Make the index start at 1 instead of 0\n    # Save the DataFrame to a CSV file\n    df.to_csv('submission.csv')\n    return(df)\n\nsubmission_model(model, test_loader)\n ","metadata":{"papermill":{"duration":8.203141,"end_time":"2023-07-11T16:31:54.818232","exception":false,"start_time":"2023-07-11T16:31:46.615091","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-24T20:26:27.205741Z","iopub.execute_input":"2023-07-24T20:26:27.206107Z","iopub.status.idle":"2023-07-24T20:26:30.358679Z","shell.execute_reply.started":"2023-07-24T20:26:27.206076Z","shell.execute_reply":"2023-07-24T20:26:30.357747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" \n# FIM","metadata":{"papermill":{"duration":0.018693,"end_time":"2023-07-11T16:31:54.855665","exception":false,"start_time":"2023-07-11T16:31:54.836972","status":"completed"},"tags":[]}},{"cell_type":"code","source":"'''file='/kaggle/working/state.db'\nos.remove(file)\n'''","metadata":{"papermill":{"duration":0.028537,"end_time":"2023-07-11T16:31:54.902918","exception":false,"start_time":"2023-07-11T16:31:54.874381","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" ","metadata":{"papermill":{"duration":0.018016,"end_time":"2023-07-11T16:31:54.939349","exception":false,"start_time":"2023-07-11T16:31:54.921333","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.018117,"end_time":"2023-07-11T16:31:54.975867","exception":false,"start_time":"2023-07-11T16:31:54.957750","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}