{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Rede Neural de Multilayer Perceptron (MLP)\n## Autor: Mariano F.M.A.S.\n### Data: 06/07/2023\n","metadata":{}},{"cell_type":"markdown","source":"# Rede Neural Artificial \n\nUma Rede Neural Artificial (ANN) é um modelo de aprendizado de máquina inspirado na estrutura e funcionamento do cérebro humano. Ela é composta por um grande número de unidades de processamento, chamadas neurônios ou nós, que estão interconectados por links chamados conexões. Cada conexão entre os neurônios carrega um peso, que pode ser pensado como a \"força\" da conexão. Esses pesos são ajustados durante o processo de treinamento para melhorar a precisão do modelo.\n \n\n<img src=\"https://mriquestions.com/uploads/3/4/5/7/34572113/perceptron-with-neuron_1.png\" alt=\"Comparação do Neurônio Artificial com o Neurônio Humano.\" width=\"600\"  >\n \n\n\nA **Rede Neural de Multilayer Perceptron (MLP)** é um tipo específico de ANN que é composta por três ou mais camadas de neurônios: uma camada de entrada, uma ou mais camadas ocultas e uma camada de saída. Cada neurônio em uma camada está conectado a todos os neurônios na camada seguinte, daí o termo \"totalmente conectado\".\n\nAqui está uma descrição mais detalhada das camadas em uma MLP:\n\n1. **Camada de entrada:** Esta é a camada que recebe os dados de entrada. O número de neurônios nesta camada geralmente corresponde ao número de características nos dados de entrada.\n\n2. **Camadas ocultas:** Estas são as camadas entre a camada de entrada e a camada de saída. Cada neurônio em uma camada oculta recebe entradas de todos os neurônios na camada anterior, aplica uma função de ativação (como a função sigmoid, tanh ou ReLU), e passa o resultado para a próxima camada. O número de camadas ocultas e o número de neurônios em cada camada são parâmetros que podem ser ajustados para melhorar o desempenho do modelo.\n\n3. **Camada de saída:** Esta é a camada que produz a saída do modelo. O número de neurônios nesta camada geralmente corresponde ao número de classes no problema de classificação (para tarefas de classificação) ou a 1 (para tarefas de regressão).\n\nDurante o treinamento, a MLP usa um algoritmo chamado backpropagation para ajustar os pesos das conexões. O objetivo é minimizar a diferença entre a saída prevista pela rede e a saída real (ou seja, o erro) para todos os exemplos de treinamento.\n\n<img src=\"https://hashdork.com/wp-content/uploads/2022/04/Neural-Network.png\" alt=\"Rede Neural de Multilayer Perceptron.\" width=\"500\"  >\n \n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport scipy\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:46:06.440226Z","iopub.execute_input":"2023-07-11T16:46:06.440995Z","iopub.status.idle":"2023-07-11T16:46:06.446299Z","shell.execute_reply.started":"2023-07-11T16:46:06.440960Z","shell.execute_reply":"2023-07-11T16:46:06.444946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport seaborn as sns\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve, matthews_corrcoef, cohen_kappa_score, classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\nfrom sklearn.metrics import average_precision_score\n\nfrom itertools import cycle \nfrom sklearn.preprocessing import label_binarize\n   \n# Checking GPU is available \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Training on device: \", device)\n# Set the random seed\nrandom_seed = 11\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:46:16.305134Z","iopub.execute_input":"2023-07-11T16:46:16.305582Z","iopub.status.idle":"2023-07-11T16:46:16.316119Z","shell.execute_reply.started":"2023-07-11T16:46:16.305551Z","shell.execute_reply":"2023-07-11T16:46:16.314796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Carregando os dados\n\nAo criar um modelo de aprendizado de máquina, é comum dividir o conjunto de dados total em três subconjuntos: treinamento, validação e teste. Cada um desses conjuntos tem um propósito específico no processo de criação e avaliação do modelo.\n\n1. **Conjunto de Treinamento**: Este é o subconjunto de dados usado para treinar o modelo. O algoritmo de aprendizado de máquina \"aprende\" ajustando seus parâmetros para minimizar o erro entre suas previsões e os valores reais para os exemplos no conjunto de treinamento.\n\n2. **Conjunto de Validação**: Este é um subconjunto de dados que é usado para ajustar os hiperparâmetros do modelo, como a taxa de aprendizado ou a profundidade de uma árvore de decisão. O conjunto de validação é usado para evitar o sobreajuste durante o treinamento, permitindo que você ajuste o modelo com base em seu desempenho em dados não vistos durante o treinamento. Em outras palavras, você usa o conjunto de validação para \"validar\" as escolhas que fez durante o treinamento e ajustar o modelo de acordo.\n\n3. **Conjunto de Teste**: Este é um subconjunto de dados que é mantido separado e não é usado durante o processo de treinamento. Depois que o modelo foi treinado e ajustado, o conjunto de teste é usado para avaliar o desempenho do modelo. Isso fornece uma estimativa imparcial de como o modelo provavelmente se sairá em dados não vistos no mundo real.\n\nA divisão típica dos dados pode ser 70% para treinamento, 15% para validação e 15% para teste, mas isso pode variar dependendo do tamanho e da natureza do conjunto de dados. Além disso, técnicas como validação cruzada podem ser usadas para fazer uso mais eficiente dos dados disponíveis.\n\nEmbora tecnicamente seja possível usar o conjunto de validação como um conjunto de teste, isso não é recomendado e pode levar a uma avaliação imprecisa do desempenho do modelo.\n\nO conjunto de validação é usado durante o processo de treinamento para ajustar os hiperparâmetros do modelo e evitar o sobreajuste. Isso significa que o modelo tem acesso indireto a esses dados durante o treinamento. Portanto, o desempenho do modelo no conjunto de validação pode ser otimista, pois o modelo foi ajustado para se sair bem nesses dados.\n\nPor outro lado, o conjunto de teste é um conjunto de dados que o modelo nunca viu durante o treinamento ou a validação. Ele fornece uma avaliação imparcial do desempenho do modelo em dados não vistos. Isso é importante para ter uma ideia de como o modelo provavelmente se sairá em um cenário do mundo real.\n\nPortanto, para uma avaliação adequada do desempenho do modelo, é melhor manter conjuntos de validação e teste separados. O conjunto de validação deve ser usado para ajustar o modelo durante o treinamento, e o conjunto de teste deve ser usado para avaliar o desempenho do modelo final.\n\n","metadata":{}},{"cell_type":"code","source":"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:46:31.452128Z","iopub.execute_input":"2023-07-11T16:46:31.452560Z","iopub.status.idle":"2023-07-11T16:46:31.460790Z","shell.execute_reply.started":"2023-07-11T16:46:31.452521Z","shell.execute_reply":"2023-07-11T16:46:31.459336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importando os dados\n\n# Dados de treinamento \ndata = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n#Separa os entre train e test\ntrain, val = train_test_split(data, test_size=0.2)\n\ntrain.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)\n\n# Dados para validação do modelo\ntest_data  = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:46:55.620438Z","iopub.execute_input":"2023-07-11T16:46:55.620924Z","iopub.status.idle":"2023-07-11T16:47:02.725575Z","shell.execute_reply.started":"2023-07-11T16:46:55.620878Z","shell.execute_reply":"2023-07-11T16:47:02.724539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Criando os dataloaders\n\nNo PyTorch, a classe `Dataset` é uma classe abstrata que representa um conjunto de dados. Ela é usada para carregar e pré-processar os dados. A classe `Dataset` deve ser estendida para fornecer métodos específicos para o conjunto de dados que você está usando.\n\nA classe `Dataset` requer que você implemente pelo menos dois métodos:\n\n1. `__len__`: Este método deve retornar o número total de amostras no conjunto de dados.\n\n2. `__getitem__`: Este método deve receber um índice e retornar a amostra correspondente do conjunto de dados.\n\nAqui está um exemplo de como você pode definir uma subclasse de `Dataset` para um conjunto de dados de imagens:\n\n \nDepois de definir a classe `Dataset`, você pode usá-la para criar um objeto `DataLoader`, que é um iterador que eficientemente carrega os dados em lotes e fornece muitas outras funcionalidades, como embaralhamento dos dados e carregamento de dados em paralelo.","metadata":{}},{"cell_type":"code","source":" \n# Definindo a classe do dataset\nclass MNISTDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        image = torch.tensor(self.data.iloc[index, 1:].values/255, dtype=torch.float32) # /255 para normalizar os Pixels\n        label = torch.tensor(self.data.iloc[index, 0], dtype=torch.long)\n        return image, label\n\n# Criando os dataloaders\ntrain_dataset = MNISTDataset(train)\nval_dataset = MNISTDataset(val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:47:06.628203Z","iopub.execute_input":"2023-07-11T16:47:06.628636Z","iopub.status.idle":"2023-07-11T16:47:06.638780Z","shell.execute_reply.started":"2023-07-11T16:47:06.628602Z","shell.execute_reply":"2023-07-11T16:47:06.637562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se `shuffle=True`, os dados serão embaralhados antes de cada época. Isso é útil para garantir que o modelo não aprenda nada das sequências específicas dos dados de entrada. Em outras palavras, embaralhar os dados garante que o modelo não seja influenciado pela ordem dos exemplos de treinamento.\n\nSe `shuffle=False`, os dados serão passados na mesma ordem a cada época. Isso pode ser útil em certos casos, como quando você está trabalhando com séries temporais e a ordem dos dados é importante.\n\nEm geral, é uma boa prática embaralhar os dados de treinamento para garantir que o modelo seja robusto e não aprenda a fazer previsões com base na ordem dos exemplos.","metadata":{}},{"cell_type":"code","source":" \n# Definindo a classe do dataset\nclass MNISTDataset_test(Dataset):\n    def __init__(self, test_data):\n        self.test_data = test_data\n    \n    def __len__(self):\n        return len(self.test_data)\n    \n    def __getitem__(self, index):\n        image = torch.tensor(self.test_data.iloc[index,:].values/255, dtype=torch.float32)\n        return image\n\n# Criando os dataloaders\ntest_dataset = MNISTDataset_test(test_data)\n \ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:58:34.657157Z","iopub.execute_input":"2023-07-11T16:58:34.657618Z","iopub.status.idle":"2023-07-11T16:58:34.666263Z","shell.execute_reply.started":"2023-07-11T16:58:34.657580Z","shell.execute_reply":"2023-07-11T16:58:34.664953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizando os Dados de Treinamento e Test ","metadata":{}},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 5, figsize=(10, 7))\n\nfor images, labels in train_loader:\n    for i, ax in enumerate(axis.flat):\n        image, label = images[i], labels[i]\n        \n        ax.imshow(image.view(28, 28), cmap='binary') # add image\n        ax.set(title = f\"{label}\") # add label\n    break  # exit the loop after the first batch\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:47:19.908262Z","iopub.execute_input":"2023-07-11T16:47:19.908689Z","iopub.status.idle":"2023-07-11T16:47:23.073611Z","shell.execute_reply.started":"2023-07-11T16:47:19.908658Z","shell.execute_reply":"2023-07-11T16:47:23.072384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelo MLP\n\n`nn.Module` é uma das classes mais importantes no PyTorch e serve como base para a construção de todos os modelos de aprendizado de máquina. É uma classe base para todos os módulos de rede neural, e seus membros ou sub-classes podem ser usados como camadas de uma rede neural.\n\nA classe `nn.Module` fornece muitas funcionalidades úteis. Aqui estão algumas das mais importantes:\n\n1. **Gerenciamento de parâmetros**: `nn.Module` mantém o controle de todos os parâmetros (pesos e bias) de uma rede neural. Você pode usar o método `parameters()` para obter uma lista de todos os parâmetros do modelo que precisam de gradiente (ou seja, que serão atualizados durante o treinamento).\n\n2. **Funcionalidades de GPU**: `nn.Module` facilita a transferência de todos os parâmetros do modelo para a GPU usando o método `to(device)`, onde `device` pode ser `cuda` para GPUs ou `cpu` para CPUs.\n\n3. **Salvando e carregando o modelo**: `nn.Module` fornece métodos para salvar e carregar o modelo, que são `state_dict()` e `load_state_dict()`, respectivamente.\n\n4. **Encapsulamento de camadas**: `nn.Module` permite que você defina suas próprias camadas e modelos personalizados, agrupando várias camadas juntas.\n\nPara criar um modelo personalizado, você normalmente define uma subclasse de `nn.Module`, implementa o método `__init__` para definir as camadas do modelo, e implementa o método `forward` para especificar como o modelo processa as entradas.\n\n\nO método `__init__` e o método `forward` são dois componentes fundamentais ao criar uma rede neural personalizada no PyTorch, estendendo a classe `nn.Module`.\n\n**__init__**: Este é o construtor da classe. É aqui que você define as diferentes camadas da sua rede neural. Cada camada é representada por uma instância de uma classe `nn.Module` (como `nn.Linear`, `nn.Conv2d`, `nn.MaxPool2d`, etc.). Quando você cria uma instância de uma camada, você especifica os parâmetros dessa camada, como o número de entradas e saídas para uma camada linear, ou o tamanho do kernel e o número de canais para uma camada convolucional.\n\n\n**forward**: Este método define como a rede neural realiza a propagação para frente (ou seja, como ela processa as entradas e calcula as saídas). Você implementa o método `forward` para usar as camadas que você definiu no `__init__` para transformar a entrada em uma saída.\n\n## Construindo um Modelo MLP\n","metadata":{}},{"cell_type":"code","source":" \nclass MNISTModel(nn.Module):\n    def __init__(self):\n        super(MNISTModel, self).__init__()\n        self.fc1 = nn.Linear(28*28, 784)  # Primeira camada oculta com 784 neurônios\n        self.fc2 = nn.Linear(784, 392)  # Segunda camada oculta com 392 neurônios\n        self.fc3 = nn.Linear(392, 196)  # Terceira camada oculta com 196 neurônios\n        self.fc4 = nn.Linear(196, 98)  # Quarta camada oculta com 98 neurônios\n        self.fc5 = nn.Linear(98, 10)  # Camada de saída com 10 neurônios (para 10 classes) \n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))  # Primeira camada oculta com função de ativação ReLU\n        x = F.relu(self.fc2(x))  # Segunda camada oculta com função de ativação ReLU\n        x = F.relu(self.fc3(x))  # Terceira camada oculta com função de ativação ReLU\n        x = F.relu(self.fc4(x))  # Quarta camada oculta com função de ativação ReLU\n        x = self.fc5(x)  # Camada de saída\n        return x \n    \n# Criando uma instância da rede neural\nmodel = MNISTModel().to(device)\n# Imprimindo a arquitetura da rede neural\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:47:29.849481Z","iopub.execute_input":"2023-07-11T16:47:29.849929Z","iopub.status.idle":"2023-07-11T16:47:29.877950Z","shell.execute_reply.started":"2023-07-11T16:47:29.849885Z","shell.execute_reply":"2023-07-11T16:47:29.876578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n##  Função de Ativação\n\nA é uma função matemática aplicada a um sinal de saída da soma ponderada dos neurônios. Ela é usada para determinar se o neurônio correspondente deve ser \"ativado\" ou não, com base nos valores de entrada recebidos.\n\nO PyTorch fornece várias funções de ativação. Aqui estão algumas das mais comuns:\n\n1. **ReLU (Rectified Linear Unit)**: É a função de ativação mais comumente usada em redes neurais e redes neurais convolucionais. Ela retorna o valor de entrada para entradas positivas e 0 para entradas negativas.\n\n   Uso: `nn.ReLU()` ou `torch.relu(input)`\n\n2. **Sigmoid**: Esta função de ativação mapeia os valores de entrada para o intervalo entre 0 e 1, tornando-a útil para a saída de probabilidades.\n\n   Uso: `nn.Sigmoid()` ou `torch.sigmoid(input)`\n\n3. **Tanh (Tangente Hiperbólica)**: Semelhante à função sigmoid, mas mapeia os valores de entrada para o intervalo entre -1 e 1.\n\n   Uso: `nn.Tanh()` ou `torch.tanh(input)`\n\n4. **Softmax**: Esta função de ativação é usada na camada de saída de redes neurais de classificação multiclasse. Ela transforma os valores de entrada em probabilidades que somam 1.\n\n   Uso: `nn.Softmax(dim)` ou `torch.softmax(input, dim)`\n\n5. **Leaky ReLU**: É uma variação da ReLU que permite pequenos valores negativos quando a entrada é menor que zero.\n\n   Uso: `nn.LeakyReLU(negative_slope=0.01)` ou `F.leaky_relu(input, negative_slope=0.01)`\n\n6. **ELU (Exponential Linear Unit)**: Semelhante à Leaky ReLU, mas a parte negativa é suavizada e aproxima-se de -1 para entradas negativas grandes.\n\n   Uso: `nn.ELU(alpha=1.0)` ou `F.elu(input, alpha=1.0)`\n\n7. **PReLU (Parametric ReLU)**: É uma versão da Leaky ReLU onde a inclinação para valores negativos é aprendida durante o treinamento.\n\n   Uso: `nn.PReLU(num_parameters=1, init=0.25)`\n\n8. **SELU (Scaled Exponential Linear Unit)**: É uma função de ativação que leva em conta a escala dos valores de entrada.\n\n   Uso: `nn.SELU()` ou `F.selu(input)`\n\n9. **GELU (Gaussian Error Linear Unit)**: É uma função de ativação que é usada em alguns modelos de redes neurais modernos, como o Transformer e o BERT.\n\n   Uso: `nn.GELU()` ou `F.gelu(input)`\n\n10. **Softplus**: É uma função de ativação que serve como uma alternativa suavizada à função ReLU.\n\n    Uso: `nn.Softplus(beta=1, threshold=20)` ou `F.softplus(input, beta=1, threshold=20)`\n\nLembre-se de que a escolha da função de ativação depende do problema específico que você está tentando resolver e do tipo de rede neural que você está usando.\n\n<img src=\"https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/62b18a8dc83132e1a479b65d_neural-network-activation-function-cheat-sheet.jpeg\" alt=\"Funções de Ativação.\" width=\"800\"  >\n","metadata":{}},{"cell_type":"markdown","source":"O PyTorch fornece uma variedade de camadas que você pode usar para construir sua rede neural. Aqui estão algumas das mais comuns:\n\n1. **Linear**: Uma camada linear realiza uma transformação linear nos dados de entrada. É também conhecida como camada totalmente conectada.\n\n2. **Convolutional (Conv1d, Conv2d, Conv3d)**: As camadas convolucionais são a pedra angular das redes neurais convolucionais (CNNs), que são comumente usadas para tarefas de processamento de imagem.\n\n3. **Pooling (MaxPool1d, MaxPool2d, MaxPool3d, AvgPool1d, etc.)**: As camadas de pooling são usadas para reduzir a dimensionalidade dos dados de entrada.\n\n4. **Dropout**: A camada de dropout é uma técnica de regularização que ajuda a prevenir o sobreajuste \"desligando\" aleatoriamente alguns neurônios durante o treinamento.\n\n5. **BatchNorm (BatchNorm1d, BatchNorm2d, BatchNorm3d)**: As camadas de normalização em lote ajudam a acelerar o treinamento e melhorar a generalização, normalizando a saída de cada camada.\n\n6. **Embedding**: A camada de incorporação é usada para converter entradas categóricas em vetores densos de tamanho fixo, geralmente para tarefas de processamento de linguagem natural.\n\n7. **RNN, LSTM, GRU**: Estas são camadas recorrentes usadas para processar sequências de dados, como séries temporais ou texto.\n\n8. **Transformer**: A camada Transformer é a base das redes de transformadores, que são usadas para tarefas de processamento de linguagem natural, como tradução automática.\n\n9. **Softmax, LogSoftmax**: Estas são camadas de ativação usadas na camada de saída de uma rede neural para tarefas de classificação.\n\n10. **ReLU, Sigmoid, Tanh, LeakyReLU, etc.**: Estas são camadas de ativação usadas para introduzir não-linearidades na rede.\n\nLembre-se de que a escolha da camada depende da tarefa específica que você está tentando resolver e do tipo de rede neural que você está usando. Além disso, muitas dessas camadas têm variantes (por exemplo, diferentes tipos de camadas de pooling ou normalização) que podem ser mais adequadas para certos tipos de dados ou tarefas.","metadata":{}},{"cell_type":"markdown","source":"# Função de Treinando\n\nDefinimos uma função para fazer o treinamento de um modelo qualquer.\n\nEssa função vai treinar o modelo por infinitas epochs, até que a acurácia pare de aumentar após um determinado número de epocas dada por `patience`.\n\nApós cada epoch, avaliamos o modelo usando o conjunto de validação.\n","metadata":{}},{"cell_type":"code","source":" \ndef train_model(model, criterion, optimizer, train_loader, val_loader, patience):\n    best_accuracy = 0.0  # Inicialize a melhor acurácia como 0\n    epochs_without_improvement = 0  # Contador para épocas sem melhoria\n    #patience => Número de épocas para esperar, depois de obter a melhor acurácia, antes de parar\n    model.train()\n    epoch= 0\n    \n    while True:                      \n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)   \n             \n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()  \n            \n        # Validação\n        accuracy, validation_loss = validate(model, val_loader, criterion)\n        print('Epoch [{}], Loss: {:.4f}, Validation Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, loss.item(), validation_loss, accuracy))\n        epoch=epoch+1\n        \n        # Verifica se a acurácia melhorou\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            epochs_without_improvement = 0  # Reseta o contador\n            torch.save(model.state_dict(), 'best_model_MLP.pth') # Salva o modelo com a melhor acurácia\n        else:\n            epochs_without_improvement += 1 # Incrementar o contador\n         # Se a acurácia não melhorar por um número 'patience' de épocas, para de treinar\n        if epochs_without_improvement == patience:\n            print('Stopping training!')\n            break\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:47:40.110885Z","iopub.execute_input":"2023-07-11T16:47:40.111309Z","iopub.status.idle":"2023-07-11T16:47:40.123821Z","shell.execute_reply.started":"2023-07-11T16:47:40.111278Z","shell.execute_reply":"2023-07-11T16:47:40.122391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model, val_loader, criterion):\n    model.eval()  # Defina o modelo para o modo de avaliação\n    correct = 0\n    total = 0\n    validation_loss = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            validation_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)   #Encontra o índice da probabilidade máxima\n            # A função torch.max() retorna dois valores: o primeiro é o valor máximo encontrado em cada coluna do tensor\n            #e o segundo é o índice do valor máximo em cada coluna. ex.: [0.2, 0.4, 0.9, 0.5] => (0.9, 2)= (valor máximo,índice)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = (correct / total) * 100\n    validation_loss = validation_loss / len(val_loader)  # Media de loss\n\n    model.train()  # Defin3 o modelo de volta ao modo de treinamento\n\n    return accuracy, validation_loss\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:47:42.915834Z","iopub.execute_input":"2023-07-11T16:47:42.916270Z","iopub.status.idle":"2023-07-11T16:47:42.926182Z","shell.execute_reply.started":"2023-07-11T16:47:42.916238Z","shell.execute_reply":"2023-07-11T16:47:42.924886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Treinamento o Modelo MLP","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()  # Loss function \noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Optimizer\npatience = 3  # Número de épocas para esperar antes de parar\n\n\ntrain_model(model, criterion, optimizer, train_loader, val_loader, patience)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:48:07.598750Z","iopub.execute_input":"2023-07-11T16:48:07.600193Z","iopub.status.idle":"2023-07-11T16:51:25.151709Z","shell.execute_reply.started":"2023-07-11T16:48:07.600144Z","shell.execute_reply":"2023-07-11T16:51:25.150318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inicialize o modelo\nmodel = MNISTModel()\n\n# Carregue o estado do modelo salvo\nmodel.load_state_dict(torch.load('best_model_MLP.pth'))\n\nmodel.eval()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:51:25.153809Z","iopub.execute_input":"2023-07-11T16:51:25.154216Z","iopub.status.idle":"2023-07-11T16:51:25.177377Z","shell.execute_reply.started":"2023-07-11T16:51:25.154181Z","shell.execute_reply":"2023-07-11T16:51:25.176188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Avaliação do Modelo\n\n##  Métricas de avaliação de modelos de classificação\n\nPara calcular as metricas de avaliação usamos os sequintes valores:\n\n**Verdadeiros Positivos (TP)**: Verdadeiros positivos são os casos em que o modelo previu a classe positiva corretamente. Em outras palavras, a classe real do exemplo era positiva e o modelo também previu a classe como positiva.\n\n**Falsos Positivos (FP)**: Falsos positivos são os casos em que o modelo previu incorretamente a classe positiva. Isso significa que a classe real do exemplo era negativa, mas o modelo previu a classe como positiva. Isso é também conhecido como um erro do Tipo I.\n\n**Verdadeiros Negativos (TN)**: Verdadeiros negativos são os casos em que o modelo previu a classe negativa corretamente. Em outras palavras, a classe real do exemplo era negativa e o modelo também previu a classe como negativa.\n\n**Falsos Negativos (FN)**: Falsos negativos são os casos em que o modelo previu incorretamente a classe negativa. Isso significa que a classe real do exemplo era positiva, mas o modelo previu a classe como negativa. Isso é também conhecido como um erro do Tipo II.\n\n\nEsses quatro valores formam a base da matriz de confusão. Além disso, várias métricas de avaliação, como precisão, recall e F1 score, são calculadas com base nesses valores. \n\n## Métricas\n\n\n1. **Accuracy (Acurácia)**: É a proporção de previsões corretas feitas pelo modelo em relação ao total de previsões. É uma métrica útil quando as classes estão bem balanceadas, mas pode ser enganosa quando as classes estão desbalanceadas. A fórmula para a acurácia é:\n\n   $$ \\text{Accuracy} = \\frac{\\text{Verdadeiros Positivos (TP) + Verdadeiros Negativos (TN)}}{\\text{Verdadeiros Positivos (TP) + Falsos Positivos (FP) + Verdadeiros Negativos (TN) + Falsos Negativos (FN)}} $$\n   \n\n\n2. **Precision (Precisão)**: É a proporção de previsões positivas que são realmente corretas. É uma métrica importante quando o custo de Falsos Positivos é alto. A fórmula para a precisão é:\n\n   $$ \\text{Precision} = \\frac{\\text{Verdadeiros Positivos (TP)}}{\\text{Verdadeiros Positivos (TP) + Falsos Positivos (FP)}} $$\n\n\n3. **Recall (Revocação ou Sensibilidade)**: É a proporção de positivos reais que foram identificados corretamente. É uma métrica importante quando o custo de Falsos Negativos é alto. A fórmula para o recall é:\n\n   $$ \\text{Recall} = \\frac{\\text{Verdadeiros Positivos (TP)}}{\\text{Verdadeiros Positivos (TP) + Falsos Negativos (FN)}} $$\n\n\n4. **F1 Score**: É a média harmônica entre a precisão e o recall. É uma métrica útil quando você precisa de um equilíbrio entre a precisão e o recall e há uma distribuição desigual de classes. A fórmula para o F1 Score é:\n\n   $$ \\text{F1 Score} = 2 * \\frac{\\text{Precision * Recall}}{\\text{Precision + Recall}} $$\n\n\nEssas métricas são comumente usadas para avaliar modelos de classificação e cada uma tem seus próprios pontos fortes e fracos, dependendo da situação específica.\n\n\n5. **Coeficiente de Kappa de Cohen**\n\nO coeficiente de Kappa de Cohen é uma estatística que é usada para medir a precisão de classificação em tarefas de classificação. É mais útil quando os dados são classificados por humanos, pois leva em consideração a possibilidade de o acordo ocorrer por acaso.\n\nO coeficiente de Kappa de Cohen varia de -1 a 1. Um valor de 1 indica que há um acordo perfeito entre os classificadores. Um valor de 0 indica que o acordo é o mesmo que seria esperado por acaso. Um valor negativo indica que o acordo é pior do que o aleatório.\n\nAqui está como o coeficiente de Kappa de Cohen é geralmente interpretado:\n\n- Valores ≤ 0: Nenhum acordo\n- 0.01–0.20: Nenhum a um leve acordo\n- 0.21–0.40: Acordo justo\n- 0.41–0.60: Acordo moderado\n- 0.61–0.80: Acordo substancial\n- 0.81–0.99: Acordo quase perfeito\n- 1: Acordo perfeito\n\nO coeficiente de Kappa de Cohen é uma medida mais robusta do que a simples porcentagem de concordância, porque leva em consideração a possibilidade de o acordo ocorrer por acaso. Isso é especialmente importante quando os dados estão desequilibrados.\n\n\n6. **Coeficiente de Correlação de Matthews (MCC)**\n\nO Coeficiente de Correlação de Matthews (MCC) é uma medida de qualidade para problemas de classificação binária. Ele leva em consideração verdadeiros e falsos positivos e negativos e é geralmente considerado uma medida equilibrada, o que significa que pode ser usado mesmo se as classes estiverem de tamanhos muito diferentes.\n\nO MCC é, em essência, uma correlação entre as observações reais e as previsões: um coeficiente de +1 representa uma previsão perfeita, 0 uma previsão média aleatória e -1 uma previsão inversa.\n\nA fórmula para o MCC é:\n\n$$ MCC = \\frac{(TP*TN - FP*FN) }{ \\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)} }$$\n\n\n\nO denominador da fórmula garante que o MCC sempre caia entre -1 e +1.\n\n7. **Matriz de Confusão**\n\nA Matriz de Confusão é uma tabela usada para descrever o desempenho de um modelo de classificação em um conjunto de dados para os quais os valores verdadeiros são conhecidos. Ela é chamada de matriz de confusão porque permite visualizar facilmente o tipo de confusão que o classificador está causando, mostrando onde o classificador está confundindo uma classe por outra.\n\n \n\nPara uma classificação binária a matriz de confusão é uma tabela 2x2. As linhas da matriz representam as classes reais, enquanto as colunas representam as classes previstas pelo modelo. A matriz é organizada da seguinte forma:\n\n\n|                     | **Previsto: Positivo** | **Previsto: Negativo** |\n|---------------------|------------------------|------------------------|\n| **Real: Positivo**  | Verdadeiros Positivos  | Falsos Negativos       |\n| **Real: Negativo**  | Falsos Positivos       | Verdadeiros Negativos  |\n\n\nA matriz de confusão é uma ferramenta poderosa para entender como seu modelo está performando e onde ele está cometendo erros. Além disso, muitas métricas de avaliação do modelo, como precisão, recall e F1 score, são calculadas com base nos valores da matriz de confusão.\n\n7. **ROC Curve**\n\nA curva ROC (Receiver Operating Characteristic) é uma ferramenta gráfica usada para avaliar o desempenho de um modelo de **classificação binária** ou diagnóstico. Ela foi desenvolvida durante a Segunda Guerra Mundial para a análise de sinais de radar e desde então tem sido usada em muitos outros campos.\n\nA curva ROC é um gráfico de duas dimensões onde a taxa de verdadeiros positivos (TPR, True Positive Rate) é plotada no eixo Y e a taxa de falsos positivos (FPR, False Positive Rate) é plotada no eixo X.  \n\nCada ponto na curva ROC representa um par de valores (FPR, TPR) correspondentes a um limiar de decisão específico. O limiar de decisão é o valor a partir do qual decidimos se uma previsão é classificada como positiva ou negativa. Ao variar o limiar de decisão, obtemos diferentes pares de valores (FPR, TPR) que formam a curva ROC.\n\nA linha diagonal do canto inferior esquerdo ao canto superior direito representa a curva ROC de um classificador aleatório (um classificador que faz previsões aleatórias). Um bom classificador tem a curva ROC mais próxima do canto superior esquerdo (alta taxa de verdadeiros positivos e baixa taxa de falsos positivos).\n\nA área sob a curva ROC (AUC, Area Under the Curve) é uma métrica que resume o desempenho do classificador. A AUC varia de 0 a 1, onde 1 representa um classificador perfeito e 0.5 representa um classificador aleatório. Quanto maior a AUC, melhor o classificador.\n\n\n\n\n\n- **Binarização dos rótulos**: Os rótulos verdadeiros (neste caso os labels 0-9) são binarizados usando a função `label_binarize` do sklearn. Isso é necessário porque a curva ROC e a AUC são calculadas para a classificação binária e precisamos de uma representação binária para a classificação multiclasse.\n\n- **Cálculo da curva ROC e AUC**: O código então entra em um loop sobre o número de classes. Para cada classe, ele calcula a curva ROC e a AUC usando as funções `roc_curve` e `auc` do sklearn, respectivamente.  \n \n8. **PR Curve**\n\nA Curva de Precisão-Recall (PR Curve) é uma ferramenta gráfica usada para avaliar o desempenho de um modelo de classificação em termos de precisão e recall. É especialmente útil em situações onde as classes estão muito desbalanceadas.\n\nA Curva de Precisão-Recall é um gráfico de duas dimensões onde a precisão é plotada no eixo Y e o recall (também conhecido como taxa de verdadeiros positivos) é plotado no eixo X.\n \nCada ponto na curva PR representa um par de valores (Recall, Precisão) correspondentes a um limiar de decisão específico. O limiar de decisão é o valor a partir do qual decidimos se uma previsão é classificada como positiva ou negativa. Ao variar o limiar de decisão, obtemos diferentes pares de valores (Recall, Precisão) que formam a curva PR.\n\nA área sob a curva PR (AUC-PR) é uma métrica que resume o desempenho do classificador. Quanto maior a AUC-PR, melhor o classificador. A AUC-PR é especialmente útil quando as classes estão desbalanceadas, pois leva em conta tanto a precisão quanto o recall, ao contrário da AUC-ROC, que pode ser excessivamente otimista em tais situações.\n  ","metadata":{}},{"cell_type":"code","source":"\n\ndef calculate_roc_auc_pr(model, dataloader):\n    model.eval()\n    y_test = []\n    y_score = []\n\n    # Iterar sobre os dados do dataloader\n    for images, labels in dataloader:\n        # Fazer a predição do modelo\n        outputs = model(images)\n        # Aplicar softmax para obter as probabilidades\n        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n        # Adicionar aos arrays\n        y_test.append(labels.numpy())\n        y_score.append(probabilities.detach().numpy())\n\n    y_test = np.concatenate(y_test)\n    y_score = np.concatenate(y_score)\n\n    # Binarizar as labels\n    y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    # Calcular ROC para cada classe\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(10):\n        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Calcular Precision-Recall para cada classe\n    precision = dict()\n    recall = dict()\n    average_precision = dict()\n    for i in range(10):\n        precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n        average_precision[i] = average_precision_score(y_test_bin[:, i], y_score[:, i])\n\n    # Plotar ROC e PR para todas as classes em um único gráfico\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n    for i in range(10):\n        axs[0].plot(fpr[i], tpr[i], label='Class %d (area = %0.5f)' % (i, roc_auc[i]))\n        axs[1].plot(recall[i], precision[i], label='Class %d (area = %0.5f)' % (i, average_precision[i]))\n    \n    ####################################################\n    axs[0].plot([0, 1], [0, 1], 'k--')\n    axs[0].set_xlim([0.0, 1.0])\n    axs[0].set_ylim([0.0, 1.05])\n    axs[0].set_xlabel('False Positive Rate')\n    axs[0].set_ylabel('True Positive Rate')\n    axs[0].set_title('Receiver Operating Characteristic')\n    axs[0].legend(loc=\"lower right\")\n\n    axs[1].set_xlim([0.0, 1.0])\n    axs[1].set_ylim([0.0, 1.05])\n    axs[1].set_xlabel('Recall')\n    axs[1].set_ylabel('Precision')\n    axs[1].set_title('Precision-Recall curve')\n    axs[1].legend(loc=\"lower right\")\n    \n    ####################################################\n    #ZOOM\n    axs[0].set_xlim([0.0, 0.5])\n    axs[0].set_ylim([0.9, 1.05])   \n    \n    axs[1].set_xlim([0.90, 1.05])\n    axs[1].set_ylim([0.5, 1.05])\n    ####################################################\n\n    plt.tight_layout()\n    plt.show()\n\n    model.train()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:51:25.179227Z","iopub.execute_input":"2023-07-11T16:51:25.179845Z","iopub.status.idle":"2023-07-11T16:51:25.198970Z","shell.execute_reply.started":"2023-07-11T16:51:25.179808Z","shell.execute_reply":"2023-07-11T16:51:25.197941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef evaluate_model(model, val_loader):\n    model.eval()  # Set the model to evaluation mode\n    true_labels = []\n    predictions = []\n    with torch.no_grad():\n        for images, labels in val_loader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            true_labels.extend(labels.numpy())\n            predictions.extend(predicted.numpy())\n\n\n    # Accuracy\n    accuracy = accuracy_score(true_labels, predictions)\n    print(\"Accuracy: \",  round(accuracy, 3))\n\n    # Precision\n    precision = precision_score(true_labels, predictions, average='weighted')\n    print(\"Precision: \",  round(precision, 3))\n\n    # Recall\n    recall = recall_score(true_labels, predictions, average='weighted')\n    print(\"Recall: \",  round(recall, 3))\n\n    # F1 Score\n    f1 = f1_score(true_labels, predictions, average='weighted')\n    print(\"F1 Score: \",  round(f1, 3))\n    \n#############################################################\n#    Está desativado pq não é um problema de classificação binaria (temos 10 classes)\n#    # Matthews Correlation Coefficient (MCC)\n#    mcc = matthews_corrcoef(true_labels, predictions)\n#    print(\"Matthews Correlation Coefficient: \",  round(mcc, 3))\n#############################################################\n\n    # Cohen's Kappa\n    kappa = cohen_kappa_score(true_labels, predictions)\n    #interpret_kappa\n    print(\"Cohen's Kappa: \",    round(kappa, 3))\n    if kappa <= 0:\n        print (\"Nenhum acordo\")\n    elif kappa <= 0.20:\n        print (\"Nenhum a um leve acordo\")\n    elif kappa <= 0.40:\n        print (\"Acordo justo\")\n    elif kappa <= 0.60:\n        print (\"Acordo moderado\")\n    elif kappa <= 0.80:\n        print (\"Acordo substancial\")\n    elif kappa < 1:\n        print (\"Acordo quase perfeito\")\n    elif kappa == 1:\n        print (\"Acordo perfeito\")\n    else:\n        print (\"Valor de Kappa inválido\")\n\n\n\n    # Classification Report\n    report = classification_report(true_labels, predictions)\n    print(\"Classification Report:\\n\", report)\n\n    # Confusion Matrix\n    cm = confusion_matrix(true_labels, predictions)\n    #print(\"Confusion Matrix:\\n\", cm)\n    \n    # Plotting Confusion Matrix\n    plt.figure(figsize=(10,7))\n    sns.heatmap(cm, annot=True, fmt='d')\n    plt.xlabel('Predicted')\n    plt.ylabel('Truth')\n    plt.show()\n    \n    # Curva de ROC e a AUC-PR\n    calculate_roc_auc_pr(model, val_loader)\n\n \n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:57:44.305264Z","iopub.execute_input":"2023-07-11T16:57:44.305735Z","iopub.status.idle":"2023-07-11T16:57:44.323483Z","shell.execute_reply.started":"2023-07-11T16:57:44.305703Z","shell.execute_reply":"2023-07-11T16:57:44.322079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:57:49.484059Z","iopub.execute_input":"2023-07-11T16:57:49.484521Z","iopub.status.idle":"2023-07-11T16:57:56.460385Z","shell.execute_reply.started":"2023-07-11T16:57:49.484487Z","shell.execute_reply":"2023-07-11T16:57:56.459140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prevendo e identificando erros","metadata":{}},{"cell_type":"code","source":"\ndef predict_and_identify_errors(model, val_loader):\n    model.eval()  # Defina o modelo para o modo de avaliação\n    correct = 0\n    total = 0\n    wrong_predictions = []\n\n    with torch.no_grad():  # Sem calcular gradientes  \n        for images, labels in val_loader:\n            outputs = model(images)  # Obtenha as previsões do modelo\n            _, predicted = torch.max(outputs.data, 1) \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            # Identificar as previsões erradas\n            wrong_indices = (predicted != labels).nonzero()[:, 0] \n            #.nonzero() retorna os índices dos elementos diferentes de zero. \n            wrong_images = images[wrong_indices]\n            wrong_labels = predicted[wrong_indices]\n            true_labels = labels[wrong_indices]\n            wrong_predictions.extend(list(zip(wrong_images, wrong_labels, true_labels)))\n\n \n    # Mostra as previsões erradas\n    print(\"Total de previsões erradas:\", total - correct )\n    print(\"Previsões erradas:\")\n    \n    # Para 2o imagens, dispostas em 2 linhas e 10 colunas\n    n_rows = 3\n    n_cols = 10\n    \n    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols, n_rows+0.3))  # Create a subplot with 1 row and 20 columns\n    axs_max=len(list(axs.flat))\n\n    for i, (img, wrong_label, true_label) in enumerate(wrong_predictions[:axs_max]): \n        # Calcula a linha e a coluna atual\n        row = i // n_cols\n        col = i % n_cols\n    \n        # Plot das imagens erradas\n        axs[row, col].imshow(img.view(28, 28), cmap='binary')\n        axs[row, col].axis('off')   \n        axs[row, col].set_title(f'P: {wrong_label.item()}, T: {true_label.item()}')  # Defina o título do subplot\n    plt.show()  # Show the plot\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:58:00.220491Z","iopub.execute_input":"2023-07-11T16:58:00.221253Z","iopub.status.idle":"2023-07-11T16:58:00.234383Z","shell.execute_reply.started":"2023-07-11T16:58:00.221216Z","shell.execute_reply":"2023-07-11T16:58:00.232825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_and_identify_errors(model, val_loader)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:58:11.163666Z","iopub.execute_input":"2023-07-11T16:58:11.164115Z","iopub.status.idle":"2023-07-11T16:58:15.706279Z","shell.execute_reply.started":"2023-07-11T16:58:11.164083Z","shell.execute_reply":"2023-07-11T16:58:15.705067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compreendendo o que está acontecendo em `wrong_predictions.extend(list(zip(wrong_images, wrong_labels, true_labels)))`:\n\n \n1. `zip(wrong_images, wrong_labels, true_labels)`: A função `zip()` pega iteráveis (pode ser zero ou mais), agrega-os em uma tupla e retorna um iterador de tuplas baseado nos iteráveis. Neste caso, `wrong_images`, `wrong_labels` e `true_labels` são agregados juntos em tuplas, onde cada tupla contém uma imagem errada, seu rótulo previsto e seu rótulo verdadeiro.\n\n2. `list(zip(wrong_images, wrong_labels, true_labels))`: A função `list()` é usada para converter o iterador de tuplas retornado por `zip()` em uma lista de tuplas.\n\n3. `wrong_predictions.extend(...)`: A função `extend()` é um método de lista que é usado para adicionar vários elementos ao final da lista existente. Neste caso, está adicionando a lista de tuplas (cada uma contendo uma imagem prevista errada, seu rótulo previsto e seu rótulo verdadeiro) ao final da lista `wrong_predictions`.\n \nCompreendendo o calculo da linha e da coluna na grade de subplots:\n\n- `row = i // n_cols`: Esta linha calcula a linha atual na grade de subplots. O operador `//` realiza uma divisão inteira, o que significa que ele divide `i` por `n_cols` e depois arredonda para baixo para o número inteiro mais próximo. Isso é usado para determinar em qual linha do subplot a imagem atual deve ser plotada. Por exemplo, se você tem 10 colunas e está na imagem 11 (índice 10, pois os índices começam em 0), `i // n_cols` seria `10 // 10 = 1`, então a imagem seria plotada na segunda linha.\n\n- `col = i % n_cols`: Esta linha calcula a coluna atual na grade de subplots. O operador `%` calcula o resto da divisão de `i` por `n_cols`. Isso é usado para determinar em qual coluna do subplot a imagem atual deve ser plotada. Por exemplo, se você tem 10 colunas e está na imagem 11 (índice 10), `i % n_cols` seria `10 % 10 = 0`, então a imagem seria plotada na primeira coluna da segunda linha.\n\nEssas duas linhas de código juntas permitem que você percorra uma grade de subplots linha por linha, preenchendo todas as colunas em uma linha antes de passar para a próxima.","metadata":{}},{"cell_type":"markdown","source":"# Submissão","metadata":{}},{"cell_type":"code","source":"\ndef submission_model(model, test_loader):\n    model.eval()  # Set the model to evaluation mode\n    predictions = []\n    with torch.no_grad():\n        for images in test_loader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            predictions.extend(predicted.numpy())\n           # print('oi')\n        # Create a DataFrame with the predictions\n        df = pd.DataFrame(predictions, columns=['Label'])\n        df['Label'] = df['Label'].astype(int)  \n        df.index.name = 'ImageId'\n        df.index += 1  # Make the index start at 1 instead of 0\n    # Save the DataFrame to a CSV file\n    df.to_csv('submission.csv')\n    return(df)\n\nsubmission_model(model, test_loader)\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:58:46.738720Z","iopub.execute_input":"2023-07-11T16:58:46.739176Z","iopub.status.idle":"2023-07-11T16:58:51.880593Z","shell.execute_reply.started":"2023-07-11T16:58:46.739144Z","shell.execute_reply":"2023-07-11T16:58:51.879457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusão\n\nNeste notebook, exploramos como treinar e avaliar um modelo de rede neural usando PyTorch. Vimos como calcular várias métricas de desempenho e como visualizá-las e interpretá-las.\n \n\n# FIM","metadata":{}}]}