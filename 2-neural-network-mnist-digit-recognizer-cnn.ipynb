{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Rede Neural Convolucional (Convolutional Neural Network - CNN)\n## Autor: Mariano F.M.A.S.\n### Data: 09/07/2023\n\n\nNeste notebook, exploramos como treinar e avaliar um modelo de Rede Neural Convolucional (CNN) usando PyTorch. Reaproveitamos as função construidas em `1_neural_network_MNIST_digit_recognizer_MLP` para treinar e calcular as métricas de desempenho.\n","metadata":{}},{"cell_type":"markdown","source":"# Rede Neural Convolucional (Convolutional Neural Network - CNN)\n\nUma Rede Neural Convolucional (Convolutional Neural Network - CNN) é um tipo de rede neural artificial projetada para processar dados com uma estrutura de grade semelhante, como uma imagem. As CNNs são uma das principais categorias de modelos para processamento de imagens e visão computacional.\n\nAs CNNs são compostas por uma ou mais camadas convolucionais, seguidas por uma ou mais camadas totalmente conectadas (como em uma rede neural multicamada). As camadas convolucionais criam mapas de características que registram uma região da imagem, enquanto as camadas totalmente conectadas minimizam o erro na classificação.\n\nAqui estão os principais componentes de uma CNN:\n\n1. **Camada Convolucional:** Esta camada usa um conjunto de filtros e uma operação de convolução para criar um mapa de características.\n\n2. **Função de Ativação / Não-linearidade (ReLU, Sigmoid, etc.):** Após cada camada convolucional, a CNN aplica uma função de ativação não linear. A função de ativação mais comum é a ReLU (Rectified Linear Unit).\n\n3. **Camada de Pooling ou Subamostragem:** Após a função de ativação, a CNN aplica uma operação de pooling para reduzir a dimensionalidade do mapa de características e evitar o overfitting. A operação de pooling mais comum é a max pooling.\n\n4. **Camada Totalmente Conectada (FC):** Após várias camadas convolucionais e de pooling, a CNN usa uma ou mais camadas totalmente conectadas para classificação.\n\n5. **Função de Perda (Softmax, Cross Entropy, etc.):** A última camada de uma CNN é geralmente uma camada softmax ou uma camada de entropia cruzada que é usada para a classificação de saída.\n\nAs CNNs têm sido muito bem-sucedidas em tarefas de visão computacional, como classificação de imagens, detecção de objetos, reconhecimento facial e muito mais.\n\n\n<img src=\"https://slideplayer.com.br/slide/15363722/93/images/10/Convolutional+Neural+Network+%28CNN%29.jpg\" alt=\"CNN.\" width=\"700\"  >\n \n\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport scipy\nimport pandas as pd\nimport seaborn as sns\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve, matthews_corrcoef, cohen_kappa_score, classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc  \n#from itertools import cycle \n \n    \n# Checking GPU is available \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Training on device: \", device)\n\nrandom_seed = 11","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:02.979502Z","iopub.execute_input":"2023-07-11T16:03:02.979927Z","iopub.status.idle":"2023-07-11T16:03:02.987819Z","shell.execute_reply.started":"2023-07-11T16:03:02.979888Z","shell.execute_reply":"2023-07-11T16:03:02.986761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Carregando os dados","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:02.989336Z","iopub.execute_input":"2023-07-11T16:03:02.989633Z","iopub.status.idle":"2023-07-11T16:03:03.012660Z","shell.execute_reply.started":"2023-07-11T16:03:02.989607Z","shell.execute_reply":"2023-07-11T16:03:03.011411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importando os dados\n\n# Dados de treinamento \ndata = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n#Separa os entre train e test\ntrain, val = train_test_split(data, test_size=0.2)\n\ntrain.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)\n\n# Dados para validação do modelo\ntest_data  = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:03.014219Z","iopub.execute_input":"2023-07-11T16:03:03.014693Z","iopub.status.idle":"2023-07-11T16:03:07.197222Z","shell.execute_reply.started":"2023-07-11T16:03:03.014664Z","shell.execute_reply":"2023-07-11T16:03:07.196246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Criando os dataloaders da CNN\n\nAgora estaremos usando os dados como imagens (matrizes de pixels) invés de vetores (1D), então modificamos o retorno da função Dataset.\n\nO método `reshape()` é usado para alterar a forma de um array sem alterar seus dados. Ele retorna um array que contém os mesmos dados que o array original, mas com uma nova forma.\n\nNo seu caso, `.reshape((1, 28, 28))` está alterando a forma do array para ter uma forma de `(1, 28, 28)`. Isso significa que o array resultante terá três dimensões, com o tamanho da primeira dimensão sendo 1, o tamanho da segunda dimensão sendo 28 e o tamanho da terceira dimensão sendo 28.\n\nEm termos de imagens, isso geralmente é usado para formatar uma imagem plana 1D em uma imagem 2D. No conjunto de dados MNIST cada imagem é de 28x28 pixels, mas as imagens são armazenadas como arrays 1D de 784 elementos. Então, `.reshape((1, 28, 28))` está reformatando essa imagem 1D em uma imagem 2D de 28x28 pixels. A dimensão extra (1) é usada para indicar o número de canais de cor na imagem. Neste caso, é 1 porque as imagens MNIST são em escala de cinza e, portanto, têm apenas um canal de cor.\n\n","metadata":{}},{"cell_type":"code","source":"# Definindo a classe do dataset\nclass MNISTDataset_CNN(Dataset):\n    def __init__(self, data):\n        self.data = data\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        #Usando o reshape\n        image = torch.tensor(self.data.iloc[index, 1:].values.astype(float).reshape((1, 28, 28))/255.0, dtype=torch.float32) \n        label = torch.tensor(self.data.iloc[index, 0], dtype=torch.long)\n        \n        return image, label\n\n# Criando os dataloaders\ntrain_dataset_CNN = MNISTDataset_CNN(train)\nval_dataset_CNN = MNISTDataset_CNN(val)\n\ntrain_loader_CNN = DataLoader(train_dataset_CNN, batch_size=64, shuffle=True)\nval_loader_CNN = DataLoader(val_dataset_CNN, batch_size=64, shuffle=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:07.199367Z","iopub.execute_input":"2023-07-11T16:03:07.199719Z","iopub.status.idle":"2023-07-11T16:03:07.207783Z","shell.execute_reply.started":"2023-07-11T16:03:07.199683Z","shell.execute_reply":"2023-07-11T16:03:07.206608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se `shuffle=True`, os dados serão embaralhados antes de cada época. Isso é útil para garantir que o modelo não aprenda nada das sequências específicas dos dados de entrada. Em outras palavras, embaralhar os dados garante que o modelo não seja influenciado pela ordem dos exemplos de treinamento.\n\nSe `shuffle=False`, os dados serão passados na mesma ordem a cada época. Isso pode ser útil em certos casos, como quando você está trabalhando com séries temporais e a ordem dos dados é importante.\n\nEm geral, é uma boa prática embaralhar os dados de treinamento para garantir que o modelo seja robusto e não aprenda a fazer previsões com base na ordem dos exemplos.","metadata":{}},{"cell_type":"code","source":"# Definindo a classe do dataset\nclass MNISTDataset_test_CNN(Dataset):\n    def __init__(self, test_data):\n        self.test_data = test_data\n    \n    def __len__(self):\n        return len(self.test_data)\n    \n    def __getitem__(self, index): \n        image = torch.tensor(self.test_data.iloc[index, :].values.astype(float).reshape((1, 28, 28))/255.0, dtype=torch.float32) \n       \n        return image\n\n# Criando os dataloaders\ntest_dataset_CNN = MNISTDataset_test_CNN(test_data)\n \ntest_loader_CNN = DataLoader(test_dataset_CNN, batch_size=64, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:07.209089Z","iopub.execute_input":"2023-07-11T16:03:07.209399Z","iopub.status.idle":"2023-07-11T16:03:07.223621Z","shell.execute_reply.started":"2023-07-11T16:03:07.209369Z","shell.execute_reply":"2023-07-11T16:03:07.222596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizando os Dados de Treinamento e Test ","metadata":{}},{"cell_type":"code","source":"fig, axis = plt.subplots(3, 5, figsize=(10, 7))\n\nfor images, labels in train_loader_CNN:\n    for i, ax in enumerate(axis.flat):\n        image, label = images[i], labels[i]\n        \n        ax.imshow(image.view(28, 28), cmap='binary') # add imagem\n        ax.set(title = f\"{label}\") # add label\n    break  \n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:07.226242Z","iopub.execute_input":"2023-07-11T16:03:07.226590Z","iopub.status.idle":"2023-07-11T16:03:09.474120Z","shell.execute_reply.started":"2023-07-11T16:03:07.226562Z","shell.execute_reply":"2023-07-11T16:03:09.473077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Função de Treinando\n\nDefinimos uma função para fazer o treinamento de um modelo qualquer.\n\nEssa função vai treinar o modelo por infinitas epochs, até que a acurácia pare de aumentar após um determinado número de epocas dada por `patience`.\n\nApós cada epoch, avaliamos o modelo usando o conjunto de validação.\n","metadata":{}},{"cell_type":"code","source":" \ndef train_model(model, criterion, optimizer, train_loader, val_loader, patience):\n    best_accuracy = 0.0  # Inicialize a melhor acurácia como 0\n    epochs_without_improvement = 0  # Contador para épocas sem melhoria\n    #patience => Número de épocas para esperar, depois de obter a melhor acurácia, antes de parar\n    model.train()\n    epoch= 0\n    \n    while True:                      \n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)   \n             \n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()  \n            \n        # Validação\n        accuracy, validation_loss = validate(model, val_loader, criterion)\n        print('Epoch [{}], Loss: {:.4f}, Validation Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, loss.item(), validation_loss, accuracy))\n        epoch=epoch+1\n        \n        # Verifica se a acurácia melhorou\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            epochs_without_improvement = 0  # Reseta o contador\n            torch.save(model.state_dict(), 'best_model_CNN.pth') # Salva o modelo com a melhor acurácia\n        else:\n            epochs_without_improvement += 1 # Incrementar o contador\n         # Se a acurácia não melhorar por um número 'patience' de épocas, para de treinar\n        if epochs_without_improvement == patience:\n            print('Stopping training!')\n            break\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:09.475404Z","iopub.execute_input":"2023-07-11T16:03:09.475717Z","iopub.status.idle":"2023-07-11T16:03:09.485167Z","shell.execute_reply.started":"2023-07-11T16:03:09.475688Z","shell.execute_reply":"2023-07-11T16:03:09.483777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model, val_loader, criterion):\n    model.eval()  # Defina o modelo para o modo de avaliação\n    correct = 0\n    total = 0\n    validation_loss = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            validation_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)   #Encontra o índice da probabilidade máxima\n            # A função torch.max() retorna dois valores: o primeiro é o valor máximo encontrado em cada coluna do tensor\n            #e o segundo é o índice do valor máximo em cada coluna. ex.: [0.2, 0.4, 0.9, 0.5] => (0.9, 2)= (valor máximo,índice)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = (correct / total) * 100\n    validation_loss = validation_loss / len(val_loader)  # Media de loss\n\n    model.train()  # Defin3 o modelo de volta ao modo de treinamento\n\n    return accuracy, validation_loss\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:09.486442Z","iopub.execute_input":"2023-07-11T16:03:09.486779Z","iopub.status.idle":"2023-07-11T16:03:09.501134Z","shell.execute_reply.started":"2023-07-11T16:03:09.486750Z","shell.execute_reply":"2023-07-11T16:03:09.500008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Construindo um Modelo CNN\n\nNo PyTorch, existem duas maneiras principais de definir uma Rede Neural Convolucional (CNN):\n\n1. **Usando `nn.Sequential`**: Esta é uma maneira mais simples e mais direta de definir uma CNN. Você pode definir todas as camadas da rede em uma única linha de código. Aqui está um exemplo:\n \n2. **Usando `nn.Module`**: Esta é uma maneira mais flexível de definir uma CNN, pois permite um controle mais granular sobre o fluxo de dados através da rede. Aqui está um exemplo:\n\n \nAmbas as abordagens resultarão em uma CNN funcional, mas a escolha entre elas depende das necessidades específicas do seu projeto. Se você precisar de um controle mais detalhado sobre a passagem para a frente da sua rede (por exemplo, se você quiser usar conexões residuais ou saltos), então a subclassificação `nn.Module` será mais apropriada. Se a sua rede for relativamente simples e direta, então `nn.Sequential` pode ser uma opção mais conveniente.\n## Modelo CNN_1 - nn.Sequential","metadata":{}},{"cell_type":"code","source":"class MNISTModel_CNN_1(nn.Module):\n    def __init__(self):\n        super(MNISTModel_CNN_1, self).__init__()\n\n        # Camadas convolucionais\n        self.conv_layers = nn.ModuleList([\n            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        ])\n\n        # Calcula a dimensão de entrada das camadas totalmente conectadas\n        self.fc_input_dim = self.calculate_fc_input_dim()\n\n        # Camadas totalmente conectadas\n        self.fc_layers = nn.ModuleList([\n            nn.Linear(self.fc_input_dim, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(), \n            nn.Linear(128, 10)\n        ])\n\n    def forward(self, x):\n        for layer in self.conv_layers:\n            x = layer(x)\n\n        x = x.view(-1, self.fc_input_dim)\n        for layer in self.fc_layers:\n            x = layer(x)\n\n        return x\n\n    def calculate_fc_input_dim(self):\n        # Cria uma entrada de exemplo e passa pelas camadas convolucionais\n        example_input = torch.zeros(1, 1, 28, 28)\n        for layer in self.conv_layers:\n            example_input = layer(example_input)\n            #output_shape = example_input.shape\n            #print(output_shape)\n        # Obtém a forma da saída das camadas convolucionais\n        output_shape = example_input.shape\n        fc_input_dim = output_shape[1] * output_shape[2] * output_shape[3]\n        return fc_input_dim\n    \nmodel_CNN_1=MNISTModel_CNN_1()\nprint(model_CNN_1)\n\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:09.502489Z","iopub.execute_input":"2023-07-11T16:03:09.502792Z","iopub.status.idle":"2023-07-11T16:03:09.524824Z","shell.execute_reply.started":"2023-07-11T16:03:09.502764Z","shell.execute_reply":"2023-07-11T16:03:09.523769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelo CNN_2 - nn.Module","metadata":{}},{"cell_type":"code","source":"'''\n\nclass MNISTModel_CNN_2(nn.Module):\n    def __init__(self):\n        super(MNISTModel_CNN_2, self).__init__()\n\n        # Primeira camada convolucional\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Segunda camada convolucional\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n\n        # Camadas totalmente conectada\n        self.fc_input_dim = self.calculate_fc_input_dim() # Calcula a dimensão de entrada das camadas totalmente conectadas\n        self.fc1 = nn.Linear(self.fc_input_dim, 512)\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        # Primeira camada convolucional com ReLU e max pooling\n        x = self.pool1(F.relu(self.conv1(x)))\n\n        # Segunda camada convolucional com ReLU e max pooling\n        x = self.pool2(F.relu(self.conv2(x)))\n\n        # Achatar a saída da camada convolucional para alimentar a camada totalmente conectada\n        x = x.view(-1, self.fc_input_dim)\n\n        # Camada totalmente conectada com ReLU\n        x = F.relu(self.fc1(x))\n\n        # Camada de saída\n        x = self.fc2(x)\n\n        return x\n\n    def calculate_fc_input_dim(self):\n        # Cria uma entrada de exemplo e passa pelas camadas convolucionais\n        example_input = torch.zeros(1, 1, 28, 28)\n        x = self.pool1(F.relu(self.conv1(example_input)))\n        x = self.pool2(F.relu(self.conv2(x)))\n\n        # Obtém a forma da saída das camadas convolucionais\n        output_shape = x.shape\n        fc_input_dim = output_shape[1] * output_shape[2] * output_shape[3]\n        return fc_input_dim\n\n  \n \n\nmodel_CNN_2=MNISTModel_CNN_2()\nprint(model_CNN_2)\n\n\n \n\n'''","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:09.526061Z","iopub.execute_input":"2023-07-11T16:03:09.526470Z","iopub.status.idle":"2023-07-11T16:03:09.535547Z","shell.execute_reply.started":"2023-07-11T16:03:09.526420Z","shell.execute_reply":"2023-07-11T16:03:09.534263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Treinamento o Modelo CNN\n","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()       # Loss function \nparametes_model=model_CNN_1.parameters()\n\noptimizer = torch.optim.Adam(parametes_model, lr=0.001)  # Optimizer\npatience = 6  # Número de épocas para esperar antes de parar\n\ntrain_model(model_CNN_1, criterion, optimizer, train_loader_CNN, val_loader_CNN, patience)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:03:09.536915Z","iopub.execute_input":"2023-07-11T16:03:09.537694Z","iopub.status.idle":"2023-07-11T16:13:36.749665Z","shell.execute_reply.started":"2023-07-11T16:03:09.537654Z","shell.execute_reply":"2023-07-11T16:13:36.748643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inicialize o modelo \nmodel_CNN_1 = MNISTModel_CNN_1()\n\n# Carregue o estado do modelo salvo\nmodel_CNN_1.load_state_dict(torch.load('/kaggle/working/best_model_CNN.pth'))\n\nmodel_CNN_1.eval()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:13:36.752625Z","iopub.execute_input":"2023-07-11T16:13:36.752997Z","iopub.status.idle":"2023-07-11T16:13:36.771230Z","shell.execute_reply.started":"2023-07-11T16:13:36.752965Z","shell.execute_reply":"2023-07-11T16:13:36.770081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Avaliação do Modelo\n\n##  Métricas de avaliação de modelos de classificação\n\nPara calcular as metricas de avaliação usamos os sequintes valores:\n\n**Verdadeiros Positivos (TP)**: Verdadeiros positivos são os casos em que o modelo previu a classe positiva corretamente. Em outras palavras, a classe real do exemplo era positiva e o modelo também previu a classe como positiva.\n\n**Falsos Positivos (FP)**: Falsos positivos são os casos em que o modelo previu incorretamente a classe positiva. Isso significa que a classe real do exemplo era negativa, mas o modelo previu a classe como positiva. Isso é também conhecido como um erro do Tipo I.\n\n**Verdadeiros Negativos (TN)**: Verdadeiros negativos são os casos em que o modelo previu a classe negativa corretamente. Em outras palavras, a classe real do exemplo era negativa e o modelo também previu a classe como negativa.\n\n**Falsos Negativos (FN)**: Falsos negativos são os casos em que o modelo previu incorretamente a classe negativa. Isso significa que a classe real do exemplo era positiva, mas o modelo previu a classe como negativa. Isso é também conhecido como um erro do Tipo II.\n\n\nEsses quatro valores formam a base da matriz de confusão. Além disso, várias métricas de avaliação, como precisão, recall e F1 score, são calculadas com base nesses valores. \n\n## Métricas\n\n\n1. **Accuracy (Acurácia)**: É a proporção de previsões corretas feitas pelo modelo em relação ao total de previsões. É uma métrica útil quando as classes estão bem balanceadas, mas pode ser enganosa quando as classes estão desbalanceadas. A fórmula para a acurácia é:\n\n   $$ \\text{Accuracy} = \\frac{\\text{Verdadeiros Positivos (TP) + Verdadeiros Negativos (TN)}}{\\text{Verdadeiros Positivos (TP) + Falsos Positivos (FP) + Verdadeiros Negativos (TN) + Falsos Negativos (FN)}} $$\n   \n\n\n2. **Precision (Precisão)**: É a proporção de previsões positivas que são realmente corretas. É uma métrica importante quando o custo de Falsos Positivos é alto. A fórmula para a precisão é:\n\n   $$ \\text{Precision} = \\frac{\\text{Verdadeiros Positivos (TP)}}{\\text{Verdadeiros Positivos (TP) + Falsos Positivos (FP)}} $$\n\n\n3. **Recall (Revocação ou Sensibilidade)**: É a proporção de positivos reais que foram identificados corretamente. É uma métrica importante quando o custo de Falsos Negativos é alto. A fórmula para o recall é:\n\n   $$ \\text{Recall} = \\frac{\\text{Verdadeiros Positivos (TP)}}{\\text{Verdadeiros Positivos (TP) + Falsos Negativos (FN)}} $$\n\n\n4. **F1 Score**: É a média harmônica entre a precisão e o recall. É uma métrica útil quando você precisa de um equilíbrio entre a precisão e o recall e há uma distribuição desigual de classes. A fórmula para o F1 Score é:\n\n   $$ \\text{F1 Score} = 2 * \\frac{\\text{Precision * Recall}}{\\text{Precision + Recall}} $$\n\n\nEssas métricas são comumente usadas para avaliar modelos de classificação e cada uma tem seus próprios pontos fortes e fracos, dependendo da situação específica.\n\n\n5. **Coeficiente de Kappa de Cohen**\n\nO coeficiente de Kappa de Cohen é uma estatística que é usada para medir a precisão de classificação em tarefas de classificação. É mais útil quando os dados são classificados por humanos, pois leva em consideração a possibilidade de o acordo ocorrer por acaso.\n\nO coeficiente de Kappa de Cohen varia de -1 a 1. Um valor de 1 indica que há um acordo perfeito entre os classificadores. Um valor de 0 indica que o acordo é o mesmo que seria esperado por acaso. Um valor negativo indica que o acordo é pior do que o aleatório.\n\nAqui está como o coeficiente de Kappa de Cohen é geralmente interpretado:\n\n- Valores ≤ 0: Nenhum acordo\n- 0.01–0.20: Nenhum a um leve acordo\n- 0.21–0.40: Acordo justo\n- 0.41–0.60: Acordo moderado\n- 0.61–0.80: Acordo substancial\n- 0.81–0.99: Acordo quase perfeito\n- 1: Acordo perfeito\n\nO coeficiente de Kappa de Cohen é uma medida mais robusta do que a simples porcentagem de concordância, porque leva em consideração a possibilidade de o acordo ocorrer por acaso. Isso é especialmente importante quando os dados estão desequilibrados.\n\n\n6. **Coeficiente de Correlação de Matthews (MCC)**\n\nO Coeficiente de Correlação de Matthews (MCC) é uma medida de qualidade para problemas de classificação binária. Ele leva em consideração verdadeiros e falsos positivos e negativos e é geralmente considerado uma medida equilibrada, o que significa que pode ser usado mesmo se as classes estiverem de tamanhos muito diferentes.\n\nO MCC é, em essência, uma correlação entre as observações reais e as previsões: um coeficiente de +1 representa uma previsão perfeita, 0 uma previsão média aleatória e -1 uma previsão inversa.\n\nA fórmula para o MCC é:\n\n$$ MCC = \\frac{(TP*TN - FP*FN) }{ \\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)} }$$\n\n\n\nO denominador da fórmula garante que o MCC sempre caia entre -1 e +1.\n\n7. **Matriz de Confusão**\n\nA Matriz de Confusão é uma tabela usada para descrever o desempenho de um modelo de classificação em um conjunto de dados para os quais os valores verdadeiros são conhecidos. Ela é chamada de matriz de confusão porque permite visualizar facilmente o tipo de confusão que o classificador está causando, mostrando onde o classificador está confundindo uma classe por outra.\n\n \n\nPara uma classificação binária a matriz de confusão é uma tabela 2x2. As linhas da matriz representam as classes reais, enquanto as colunas representam as classes previstas pelo modelo. A matriz é organizada da seguinte forma:\n\n\n|                     | **Previsto: Positivo** | **Previsto: Negativo** |\n|---------------------|------------------------|------------------------|\n| **Real: Positivo**  | Verdadeiros Positivos  | Falsos Negativos       |\n| **Real: Negativo**  | Falsos Positivos       | Verdadeiros Negativos  |\n\n\nA matriz de confusão é uma ferramenta poderosa para entender como seu modelo está performando e onde ele está cometendo erros. Além disso, muitas métricas de avaliação do modelo, como precisão, recall e F1 score, são calculadas com base nos valores da matriz de confusão.\n\n7. **ROC Curve**\n\nA curva ROC (Receiver Operating Characteristic) é uma ferramenta gráfica usada para avaliar o desempenho de um modelo de classificação binária ou diagnóstico. Ela foi desenvolvida durante a Segunda Guerra Mundial para a análise de sinais de radar e desde então tem sido usada em muitos outros campos.\n\nA curva ROC é um gráfico de duas dimensões onde a taxa de verdadeiros positivos (TPR, True Positive Rate) é plotada no eixo Y e a taxa de falsos positivos (FPR, False Positive Rate) é plotada no eixo X.  \n\nCada ponto na curva ROC representa um par de valores (FPR, TPR) correspondentes a um limiar de decisão específico. O limiar de decisão é o valor a partir do qual decidimos se uma previsão é classificada como positiva ou negativa. Ao variar o limiar de decisão, obtemos diferentes pares de valores (FPR, TPR) que formam a curva ROC.\n\nA linha diagonal do canto inferior esquerdo ao canto superior direito representa a curva ROC de um classificador aleatório (um classificador que faz previsões aleatórias). Um bom classificador tem a curva ROC mais próxima do canto superior esquerdo (alta taxa de verdadeiros positivos e baixa taxa de falsos positivos).\n\nA área sob a curva ROC (AUC, Area Under the Curve) é uma métrica que resume o desempenho do classificador. A AUC varia de 0 a 1, onde 1 representa um classificador perfeito e 0.5 representa um classificador aleatório. Quanto maior a AUC, melhor o classificador.\n\n\n\n\n\n- **Binarização dos rótulos**: Os rótulos verdadeiros (neste caso os labels 0-9) são binarizados usando a função `label_binarize` do sklearn. Isso é necessário porque a curva ROC e a AUC são calculadas para a classificação binária e precisamos de uma representação binária para a classificação multiclasse.\n\n- **Cálculo da curva ROC e AUC**: O código então entra em um loop sobre o número de classes. Para cada classe, ele calcula a curva ROC e a AUC usando as funções `roc_curve` e `auc` do sklearn, respectivamente.  \n \n8. **PR Curve**\n\nA Curva de Precisão-Recall (PR Curve) é uma ferramenta gráfica usada para avaliar o desempenho de um modelo de classificação em termos de precisão e recall. É especialmente útil em situações onde as classes estão muito desbalanceadas.\n\nA Curva de Precisão-Recall é um gráfico de duas dimensões onde a precisão é plotada no eixo Y e o recall (também conhecido como taxa de verdadeiros positivos) é plotado no eixo X.\n \nCada ponto na curva PR representa um par de valores (Recall, Precisão) correspondentes a um limiar de decisão específico. O limiar de decisão é o valor a partir do qual decidimos se uma previsão é classificada como positiva ou negativa. Ao variar o limiar de decisão, obtemos diferentes pares de valores (Recall, Precisão) que formam a curva PR.\n\nA área sob a curva PR (AUC-PR) é uma métrica que resume o desempenho do classificador. Quanto maior a AUC-PR, melhor o classificador. A AUC-PR é especialmente útil quando as classes estão desbalanceadas, pois leva em conta tanto a precisão quanto o recall, ao contrário da AUC-ROC, que pode ser excessivamente otimista em tais situações.\n \n \n A curva de ROC e a AUC-PR são calculadas para problemas de **classificação binária**. Se você está trabalhando com um problema de classificação multiclasse, você pode precisar adaptar o código para calcular a curva de Precisão-Recall e AUC-PR para cada classe individualmente.\n  \n","metadata":{}},{"cell_type":"code","source":"\n\ndef calculate_roc_auc(model, dataloader):\n    model.eval()\n    y_test = []\n    y_score = []\n\n    # Iterar sobre os dados do dataloader\n    for images, labels in dataloader:\n        # Fazer a predição do modelo\n        outputs = model(images)\n        # Aplicar softmax para obter as probabilidades\n        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n        # Adicionar aos arrays\n        y_test.append(labels.numpy())\n        y_score.append(probabilities.detach().numpy())\n\n    y_test = np.concatenate(y_test)\n    y_score = np.concatenate(y_score)\n\n    # Binarizar as labels\n    y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    # Calcular ROC para cada classe\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(10):\n        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Calcular Precision-Recall para cada classe\n    precision = dict()\n    recall = dict()\n    average_precision = dict()\n    for i in range(10):\n        precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n        average_precision[i] = average_precision_score(y_test_bin[:, i], y_score[:, i])\n\n    # Plotar ROC e PR para todas as classes em um único gráfico\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n    for i in range(10):\n        axs[0].plot(fpr[i], tpr[i], label='Class %d (area = %0.5f)' % (i, roc_auc[i]))\n        axs[1].plot(recall[i], precision[i], label='Class %d (area = %0.5f)' % (i, average_precision[i]))\n    \n    ####################################################\n    axs[0].plot([0, 1], [0, 1], 'k--')\n    axs[0].set_xlim([0.0, 1.0])\n    axs[0].set_ylim([0.0, 1.05])\n    axs[0].set_xlabel('False Positive Rate')\n    axs[0].set_ylabel('True Positive Rate')\n    axs[0].set_title('Receiver Operating Characteristic')\n    axs[0].legend(loc=\"lower right\")\n\n    axs[1].set_xlim([0.0, 1.0])\n    axs[1].set_ylim([0.0, 1.05])\n    axs[1].set_xlabel('Recall')\n    axs[1].set_ylabel('Precision')\n    axs[1].set_title('Precision-Recall curve')\n    axs[1].legend(loc=\"lower right\")\n    \n    ####################################################\n    #ZOOM\n    axs[0].set_xlim([0.0, 0.5])\n    axs[0].set_ylim([0.9, 1.05])   \n    \n    axs[1].set_xlim([0.90, 1.05])\n    axs[1].set_ylim([0.5, 1.05])\n    ####################################################\n\n    plt.tight_layout()\n    plt.show()\n\n    model.train()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:13:36.772997Z","iopub.execute_input":"2023-07-11T16:13:36.773355Z","iopub.status.idle":"2023-07-11T16:13:36.789599Z","shell.execute_reply.started":"2023-07-11T16:13:36.773324Z","shell.execute_reply":"2023-07-11T16:13:36.788216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef evaluate_model(model, val_loader):\n    model.eval()  # Set the model to evaluation mode\n    true_labels = []\n    predictions = []\n    with torch.no_grad():\n        for images, labels in val_loader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            true_labels.extend(labels.numpy())\n            predictions.extend(predicted.numpy())\n\n\n    # Accuracy\n    accuracy = accuracy_score(true_labels, predictions)\n    print(\"Accuracy: \",  round(accuracy, 3))\n\n    # Precision\n    precision = precision_score(true_labels, predictions, average='weighted')\n    print(\"Precision: \",  round(precision, 3))\n\n    # Recall\n    recall = recall_score(true_labels, predictions, average='weighted')\n    print(\"Recall: \",  round(recall, 3))\n\n    # F1 Score\n    f1 = f1_score(true_labels, predictions, average='weighted')\n    print(\"F1 Score: \",  round(f1, 3))\n    \n#############################################################\n#    Está desativado pq não é um problema de classificação binaria (temos 10 classes)\n#    # Matthews Correlation Coefficient (MCC)\n#    mcc = matthews_corrcoef(true_labels, predictions)\n#    print(\"Matthews Correlation Coefficient: \",  round(mcc, 3))\n#############################################################\n\n    # Cohen's Kappa\n    kappa = cohen_kappa_score(true_labels, predictions)\n    #interpret_kappa\n    print(\"Cohen's Kappa: \",    round(kappa, 3))\n    if kappa <= 0:\n        print (\"Nenhum acordo\")\n    elif kappa <= 0.20:\n        print (\"Nenhum a um leve acordo\")\n    elif kappa <= 0.40:\n        print (\"Acordo justo\")\n    elif kappa <= 0.60:\n        print (\"Acordo moderado\")\n    elif kappa <= 0.80:\n        print (\"Acordo substancial\")\n    elif kappa < 1:\n        print (\"Acordo quase perfeito\")\n    elif kappa == 1:\n        print (\"Acordo perfeito\")\n    else:\n        print (\"Valor de Kappa inválido\")\n\n\n\n    # Classification Report\n    report = classification_report(true_labels, predictions)\n    print(\"Classification Report:\\n\", report)\n\n    # Confusion Matrix\n    cm = confusion_matrix(true_labels, predictions)\n    #print(\"Confusion Matrix:\\n\", cm)\n    \n    # Plotting Confusion Matrix\n    plt.figure(figsize=(10,7))\n    sns.heatmap(cm, annot=True, fmt='d')\n    plt.xlabel('Predicted')\n    plt.ylabel('Truth')\n    plt.show()\n    \n    # Curva de ROC e a AUC-PR\n    calculate_roc_auc(model, val_loader)\n \n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:13:36.791488Z","iopub.execute_input":"2023-07-11T16:13:36.792445Z","iopub.status.idle":"2023-07-11T16:13:36.807367Z","shell.execute_reply.started":"2023-07-11T16:13:36.792401Z","shell.execute_reply":"2023-07-11T16:13:36.806454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model_CNN_1, val_loader_CNN)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:14:30.068277Z","iopub.execute_input":"2023-07-11T16:14:30.068675Z","iopub.status.idle":"2023-07-11T16:14:37.155327Z","shell.execute_reply.started":"2023-07-11T16:14:30.068644Z","shell.execute_reply":"2023-07-11T16:14:37.154202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prevendo e identificando erros","metadata":{}},{"cell_type":"code","source":"\ndef predict_and_identify_errors(model, val_loader):\n    model.eval()  # Defina o modelo para o modo de avaliação\n    correct = 0\n    total = 0\n    wrong_predictions = []\n\n    with torch.no_grad():  # Sem calcular gradientes  \n        for images, labels in val_loader:\n            outputs = model(images)  # Obtenha as previsões do modelo\n            _, predicted = torch.max(outputs.data, 1) \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            # Identificar as previsões erradas\n            wrong_indices = (predicted != labels).nonzero()[:, 0] \n            #.nonzero() retorna os índices dos elementos diferentes de zero. \n            wrong_images = images[wrong_indices]\n            wrong_labels = predicted[wrong_indices]\n            true_labels = labels[wrong_indices]\n            wrong_predictions.extend(list(zip(wrong_images, wrong_labels, true_labels)))\n\n \n    # Mostra as previsões erradas\n    print(\"Total de previsões erradas:\", total - correct )\n    print(\"Previsões erradas:\")\n    \n    # Para 2o imagens, dispostas em 2 linhas e 10 colunas\n    n_rows = 3\n    n_cols = 10\n    \n    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols, n_rows+0.3))  # Create a subplot with 1 row and 20 columns\n    axs_max=len(list(axs.flat))\n\n    for i, (img, wrong_label, true_label) in enumerate(wrong_predictions[:axs_max]): \n        # Calcula a linha e a coluna atual\n        row = i // n_cols\n        col = i % n_cols\n    \n        # Plot das imagens erradas\n        axs[row, col].imshow(img.view(28, 28), cmap='binary')\n        axs[row, col].axis('off')   \n        axs[row, col].set_title(f'P: {wrong_label.item()}, T: {true_label.item()}')  # Defina o título do subplot\n    plt.show()  # Show the plot\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:14:55.708805Z","iopub.execute_input":"2023-07-11T16:14:55.709239Z","iopub.status.idle":"2023-07-11T16:14:55.721980Z","shell.execute_reply.started":"2023-07-11T16:14:55.709203Z","shell.execute_reply":"2023-07-11T16:14:55.721142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_and_identify_errors(model_CNN_1, val_loader_CNN)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:14:59.043410Z","iopub.execute_input":"2023-07-11T16:14:59.044101Z","iopub.status.idle":"2023-07-11T16:15:03.426184Z","shell.execute_reply.started":"2023-07-11T16:14:59.044065Z","shell.execute_reply":"2023-07-11T16:15:03.425121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissão","metadata":{}},{"cell_type":"code","source":"\ndef submission_model(model, test_loader):\n    model.eval()  # Set the model to evaluation mode\n    predictions = []\n    with torch.no_grad():\n        for images in test_loader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            predictions.extend(predicted.numpy())\n           # print('oi')\n        # Create a DataFrame with the predictions\n        df = pd.DataFrame(predictions, columns=['Label'])\n        df['Label'] = df['Label'].astype(int)  \n        df.index.name = 'ImageId'\n        df.index += 1  # Make the index start at 1 instead of 0\n    # Save the DataFrame to a CSV file\n    df.to_csv('submission.csv')\n    return(df)\n\nsubmission_model(model_CNN_1, test_loader_CNN)\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:13:49.132677Z","iopub.execute_input":"2023-07-11T16:13:49.133057Z","iopub.status.idle":"2023-07-11T16:13:55.920795Z","shell.execute_reply.started":"2023-07-11T16:13:49.133025Z","shell.execute_reply":"2023-07-11T16:13:55.919774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" \n# FIM","metadata":{}},{"cell_type":"code","source":"#os.remove(\"/kaggle/working/submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:13:55.922369Z","iopub.execute_input":"2023-07-11T16:13:55.923338Z","iopub.status.idle":"2023-07-11T16:13:55.928008Z","shell.execute_reply.started":"2023-07-11T16:13:55.923294Z","shell.execute_reply":"2023-07-11T16:13:55.926874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}